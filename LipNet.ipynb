{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a3573a47-3689-4668-b62f-5c8451b2b4e9",
      "metadata": {
        "id": "a3573a47-3689-4668-b62f-5c8451b2b4e9",
        "tags": []
      },
      "source": [
        "# 0. Install and Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b24af50c-20b8-409d-ad78-30a933fdd669",
      "metadata": {
        "id": "b24af50c-20b8-409d-ad78-30a933fdd669",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import cv2\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "c7b6d7a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "floder = \"..\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a19e88e-c7b9-45c1-ae1e-f2109329c71b",
      "metadata": {
        "id": "7a19e88e-c7b9-45c1-ae1e-f2109329c71b",
        "tags": []
      },
      "source": [
        "# 1. Build Data Loading Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "id": "ec735e0b-ec98-4eb0-8f49-c35527d6670a",
      "metadata": {
        "id": "ec735e0b-ec98-4eb0-8f49-c35527d6670a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "vocab = [x for x in \"กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรลวศษสหฬอฮๆะาิีึืใไเแ่้็๊๋โฤ์ฯุูำั123456789\"] #define \n",
        "\n",
        "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, mask_token=None, oov_token=\"\")\n",
        "num_to_char = tf.keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), mask_token=None, oov_token=\"\", invert=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "8548cc59-6dfc-4acc-abc3-3e65212db02e",
      "metadata": {
        "id": "8548cc59-6dfc-4acc-abc3-3e65212db02e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def load_video(path: str):\n",
        "    \"\"\"convert video to list of frame\n",
        "    path : path of video \"\"\"\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "        ret, frame = cap.read()\n",
        "        frame_crop = frame\n",
        "        frame = tf.image.rgb_to_grayscale(frame)\n",
        "        frames.append(frame)\n",
        "\n",
        "    cap.release()\n",
        "    \n",
        "    mean = tf.math.reduce_mean(frames)\n",
        "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
        "    return tf.cast((frames - mean), tf.float32) / std #nomalization\n",
        "\n",
        "\n",
        "def load_alignments(path: str):\n",
        "    \"\"\"load data alignments in format text files alignment\n",
        "    path : path of alignments\n",
        "    file fomat  0 0 sil \n",
        "                0 20418 กระบวน \n",
        "                ...\n",
        "                128727 352800 sil\n",
        "    \"\"\"\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "    tokens = []\n",
        "    for line in lines:\n",
        "        line = line.split() # covert string space to list\n",
        "        if line[2] != 'sil':\n",
        "            tokens = [*tokens, line[2]]\n",
        "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))\n",
        "\n",
        "\n",
        "def load_data(path: str):\n",
        "    \"\"\"load data to convert video and download file alignment\"\"\"\n",
        "    path = bytes.decode(path.numpy())\n",
        "    path = path.split('/')[-1]\n",
        "    path = path[::-1].split('.', 1)[-1]\n",
        "    file_name = path[::-1]\n",
        "\n",
        "\n",
        "    video_path = f'{floder}/data/s1/{file_name}.mp4'\n",
        "    alignment_path = f'{floder}/data/alignments/s1/{file_name}.align'\n",
        "\n",
        "\n",
        "    frames = load_video(video_path)\n",
        "    alignments = load_alignments(alignment_path)\n",
        "\n",
        "    return frames, alignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6871031a-b0ba-4c76-a852-f6329b0f2606",
      "metadata": {
        "id": "6871031a-b0ba-4c76-a852-f6329b0f2606",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def mappable_function(path:str) ->List[str]:\n",
        "    \"\"\"map data video and alignments file\n",
        "    path : path of alignment or video\"\"\"\n",
        "    result = tf.py_function(load_data, [path],  (tf.float32, tf.int64))\n",
        "    if len(result[1]) > 78:\n",
        "        tf.print(path)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c40a7eb4-0c3e-4eab-9291-5611cb68ce08",
      "metadata": {
        "id": "c40a7eb4-0c3e-4eab-9291-5611cb68ce08",
        "tags": []
      },
      "source": [
        "# 2. Create Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "23e5de2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "A = (tf.data.Dataset\n",
        "     .range(1, 5, output_type=tf.int32)\n",
        "     .map(lambda x: tf.fill([x], x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "e35896bb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(3,), dtype=int32, numpy=array([3, 3, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 4, 4, 4], dtype=int32)>]"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "e8cac94c",
      "metadata": {},
      "outputs": [],
      "source": [
        "B = A.padded_batch(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "77455262",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              " array([[1, 0],\n",
              "        [2, 2]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
              " array([[3, 3, 3, 0],\n",
              "        [4, 4, 4, 4]], dtype=int32)>]"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "89a5e7ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = tf.data.Dataset.list_files(f'{floder}/data/s1/*.mp4')\n",
        "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
        "data = data.map(mappable_function)\n",
        "\n",
        "# data = data.padded_batch(2, padded_shapes=([200,None, None,None],[79]), drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "id": "f066fea2-91b1-42ed-a67d-00566a1a53ff",
      "metadata": {
        "id": "f066fea2-91b1-42ed-a67d-00566a1a53ff",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original data :  36060\n",
            "padded data :  18030\n",
            "Length of train dataset: 500\n",
            "Length of test dataset: 17530\n"
          ]
        }
      ],
      "source": [
        "data = tf.data.Dataset.list_files(f'{floder}/s1/*.mp4')\n",
        "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
        "data = data.map(mappable_function)\n",
        "print('original data : ', (tf.data.experimental.cardinality(data).numpy()))\n",
        "# for batch in data:\n",
        "#     try:\n",
        "#         tensor1, tensor2 = batch\n",
        "#         if  tensor2.shape[0] > 78:\n",
        "#             print(tensor2.shape[0])\n",
        "#     except cv2.error as e:\n",
        "#         print(f\"OpenCV Error: {e}\")\n",
        "data = data.padded_batch(2, padded_shapes=([200,None, None,None],[79]), drop_remainder=True)\n",
        "print('padded data : ', (tf.data.experimental.cardinality(data).numpy()))\n",
        "data = data.prefetch(tf.data.AUTOTUNE)\n",
        "# Added for split train  & train\n",
        "train = data.take(500)\n",
        "#test = data.skip(100)\n",
        "test = data.skip(500)\n",
        "train_length = tf.data.experimental.cardinality(train).numpy()\n",
        "\n",
        "# Get the length of the `test` dataset\n",
        "test_length = tf.data.experimental.cardinality(test).numpy()\n",
        "\n",
        "print(\"Length of train dataset:\", train_length)\n",
        "print(\"Length of test dataset:\", test_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "424be4d4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of train dataset: 16000\n",
            "Length of test dataset: 2030\n"
          ]
        }
      ],
      "source": [
        "train_length = tf.data.experimental.cardinality(train).numpy()\n",
        "\n",
        "# Get the length of the `test` dataset\n",
        "test_length = tf.data.experimental.cardinality(test).numpy()\n",
        "\n",
        "print(\"Length of train dataset:\", train_length)\n",
        "print(\"Length of test dataset:\", test_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "id": "5cf2d676-93a9-434c-b3c7-bdcc2577b2e7",
      "metadata": {
        "id": "5cf2d676-93a9-434c-b3c7-bdcc2577b2e7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "test2 = data.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "id": "efa6cd46-7079-46c0-b45b-832f339f6cb0",
      "metadata": {
        "id": "efa6cd46-7079-46c0-b45b-832f339f6cb0",
        "outputId": "c27b9c8a-52a0-42f2-cb60-73e3283e36e6",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2, 57, 43, 40, 25, 47, 43, 34, 66, 56, 26, 25, 23, 49, 37, 49,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [31, 68,  7, 55, 26, 26, 25, 49, 57, 43, 47,  8,  8, 46,  7,  7,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "execution_count": 228,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val = test2.next(); val[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f47733c-83bc-465c-b118-b198b492ad37",
      "metadata": {
        "id": "0f47733c-83bc-465c-b118-b198b492ad37",
        "tags": []
      },
      "source": [
        "# 3. Design the Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "id": "d8e9a497-191b-4842-afbd-26f5e13c43ba",
      "metadata": {
        "id": "d8e9a497-191b-4842-afbd-26f5e13c43ba",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "id": "f9171056-a352-491a-9ed9-92b28ced268e",
      "metadata": {
        "id": "f9171056-a352-491a-9ed9-92b28ced268e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# designing model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv3D(128, 3, input_shape=(200, 46, 140, 1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(256, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(200, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "id": "e5c2eae0-c359-41a4-97a0-75c44dccb7d1",
      "metadata": {
        "id": "e5c2eae0-c359-41a4-97a0-75c44dccb7d1",
        "outputId": "6221d1e1-4db8-4b8b-949e-13ebf22debf3",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ],
      "source": [
        "yhat = model.predict(val[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "id": "cb86657d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 200, 79)"
            ]
          },
          "execution_count": 246,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yhat.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec02176-5c26-46c3-aff7-8352e6563c7d",
      "metadata": {
        "id": "2ec02176-5c26-46c3-aff7-8352e6563c7d",
        "tags": []
      },
      "source": [
        "# 4. Setup Training Options and Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "id": "ab015fd0-7fb4-4d5d-9fa2-30a05dbd515a",
      "metadata": {
        "id": "ab015fd0-7fb4-4d5d-9fa2-30a05dbd515a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class LossHistoryAndSave(keras.callbacks.Callback):\n",
        "    def __init__(self, file_path):\n",
        "        super().__init__()\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.file_path = file_path\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        \n",
        "        # Save loss values to a file\n",
        "        with open(self.file_path, 'a') as file:\n",
        "            file.write(f'Epoch {epoch + 1}: Training Loss: {logs.get(\"loss\")}, Validation Loss: {logs.get(\"val_loss\")}\\n')\n",
        "\n",
        "class ProduceExample(tf.keras.callbacks.Callback): \n",
        "    def __init__(self, dataset) -> None: \n",
        "        self.dataset = dataset.as_numpy_iterator()\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
        "        data = self.dataset.next()\n",
        "        yhat = self.model.predict(data[0])\n",
        "        decoded = tf.keras.backend.ctc_decode(yhat, [200,200], greedy=False)[0][0].numpy()\n",
        "        for x in range(len(yhat)):           \n",
        "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
        "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
        "            print('~'*100)\n",
        "\n",
        "def CTCLoss(y_true, y_pred):\n",
        "    \"\"\"define loss evaluation\n",
        "    y_true : ground true\n",
        "    y_pred : model predict data\n",
        "    \"\"\"\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    #ignore_longer_outputs_than_inputs=True\n",
        "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    \"\"\"learning rate\n",
        "    epoch : epoch each dataset\n",
        "    lr : learning rate\n",
        "    \"\"\"\n",
        "    if epoch < 30:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "id": "04be90d8-2482-46f9-b513-d5f4f8001c7e",
      "metadata": {
        "id": "04be90d8-2482-46f9-b513-d5f4f8001c7e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=CTCLoss)\n",
        "checkpoint_callback = ModelCheckpoint(f'{floder}/checkpoint_1/checkpoint', monitor='val_loss',save_weights_only=True)\n",
        "schedule_callback = LearningRateScheduler(scheduler)\n",
        "loss_history_and_save = LossHistoryAndSave(f\"{floder}/loss_log/loss_history.txt\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"{floder}/logs\")\n",
        "example_callback = ProduceExample(test)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 12/500 [..............................] - ETA: 35:23 - loss: 96.8230"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[309], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mexample_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_history_and_save\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschedule_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(train, validation_data=test, epochs=100, batch_size=64, callbacks=[example_callback, early_stopping, tensorboard_callback, loss_history_and_save, checkpoint_callback, schedule_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa8ee94b-89f7-4733-8a0c-a86f86ff590a",
      "metadata": {
        "id": "fa8ee94b-89f7-4733-8a0c-a86f86ff590a",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "# 5. Make a Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01fa7204-ce0e-49a8-8dbd-14fe5dfead40",
      "metadata": {
        "id": "01fa7204-ce0e-49a8-8dbd-14fe5dfead40",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n",
        "#output = 'checkpoints.zip'\n",
        "#gdown.download(url, output, quiet=False)\n",
        "#gdown.extractall('checkpoints.zip', 'models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1681718b-1169-410c-933f-bd051da9b718",
      "metadata": {
        "id": "1681718b-1169-410c-933f-bd051da9b718"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.optimizers import legacy\n",
        "\n",
        "# # define your optimizer as a legacy optimizer\n",
        "# optimizer = legacy.Adam()\n",
        "\n",
        "# model.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "id": "247f664d-3c87-4e96-946e-930dad0e1c2c",
      "metadata": {
        "id": "247f664d-3c87-4e96-946e-930dad0e1c2c",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f19f8110100>"
            ]
          },
          "execution_count": 275,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model.load_weights('/home/somkiat/Lip_reading/checkpoint_1/checkpoint')\n",
        "model.load_weights(f'../data/checkpoint_1/checkpoint')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "38546dc2-bee9-4837-864b-8a884df40ad7",
      "metadata": {
        "id": "38546dc2-bee9-4837-864b-8a884df40ad7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "test_data = test.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a43621f0-229d-4c0d-9554-9c3a3da9c61a",
      "metadata": {
        "id": "a43621f0-229d-4c0d-9554-9c3a3da9c61a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "sample = test_data.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-25 10:01:11.677306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
            "2023-11-25 10:01:11.715210: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
            "2023-11-25 10:01:11.770591: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.770614: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.770626: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.770637: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.770649: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.772323: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.772340: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.780016: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.795722: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.795738: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:13.362744: W tensorflow/tsl/framework/bfc_allocator.cc:366] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n"
          ]
        }
      ],
      "source": [
        "eva_true = []\n",
        "eva_pred = []\n",
        "for sample in test_data:\n",
        "    try:\n",
        "        for i in range(0, 2):\n",
        "            y_true = []\n",
        "            for j in sample[1][i]:\n",
        "                if j != 0:\n",
        "                    y_true.append(j)\n",
        "            yhat = model.predict(sample[0])\n",
        "            eva_true.append(''.join([string.decode('utf-8') for string in num_to_char(y_true).numpy()]))                                                                                      \n",
        "            y_pred = []\n",
        "            for k in yhat[i]:\n",
        "                sorted_array = np.sort(k)[::-1]\n",
        "                # Get the fifth largest value\n",
        "                top_five_indices = np.argsort(k)[-5:]\n",
        "\n",
        "                # Replace values not in the top five with 0\n",
        "                result_array = np.where(np.isin(np.arange(len(k)), top_five_indices), k, 0)\n",
        "                top_five_indices = np.argsort(result_array)[-5:]\n",
        "                result_array = np.zeros(np.max(top_five_indices) + 1)\n",
        "                result_array[top_five_indices] = top_five_indices  # Y\n",
        "                result_array = result_array[result_array != 0]\n",
        "                top_five = []\n",
        "                for x in result_array:\n",
        "                    top_five.append(x)\n",
        "                y_pred.append(top_five)\n",
        "            top_one = []\n",
        "            for m in range(0, len(y_true)):\n",
        "                if y_true[m] in y_pred[m]:\n",
        "                    top_one.append(y_true[m])\n",
        "                else:\n",
        "                    # top_one.append(max)\n",
        "                    top_one.append(79)\n",
        "            eva_pred.append(''.join([string.decode('utf-8') for string in num_to_char(top_one).numpy()]))\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['แล้ว็นการัาน',\n",
              " 'แล้วเมงไกน',\n",
              " 'ใราน',\n",
              " 'นแา',\n",
              " 'ใ้น่อง',\n",
              " 'น้องเป็นแ',\n",
              " 'กรัะค',\n",
              " 'ะ่นาค',\n",
              " 'เาะวก็อคิ',\n",
              " 'แต่รายะัััง่',\n",
              " 'งมกา',\n",
              " 'น',\n",
              " 'งก',\n",
              " 'ัอยาน',\n",
              " 'แก้อนจั',\n",
              " 'แต่วรก',\n",
              " 'แั',\n",
              " 'แา',\n",
              " 'ี',\n",
              " 'เกิัน',\n",
              " 'ราร',\n",
              " 'กัก',\n",
              " 'เะกเอกกกนนกายริง',\n",
              " 'วมา',\n",
              " 'นทกันเย',\n",
              " 'เาั่มัน',\n",
              " 'ัใก้ม',\n",
              " 'นูน',\n",
              " 'ั่ัรเรื่อง',\n",
              " 'วใัเมน',\n",
              " '่ารก',\n",
              " '',\n",
              " '่เกมนงเนี่',\n",
              " 'าง',\n",
              " 'งงเป็นน',\n",
              " 'เล่ยแนั่',\n",
              " 'ไม่ระ',\n",
              " 'นะ',\n",
              " '็ก',\n",
              " '',\n",
              " 'เาะ้กน่า',\n",
              " 'เ่่อ่งไ',\n",
              " 'ร',\n",
              " 'ียนเ',\n",
              " 'ยาไ้ย',\n",
              " 'แตรวเร็',\n",
              " 'เ็นที่',\n",
              " 'น',\n",
              " 'กอะไร',\n",
              " 'ง',\n",
              " 'น่ค',\n",
              " 'แต่กนมั่ายบ',\n",
              " 'แล้วกว',\n",
              " 'นากเ',\n",
              " 'เีวาน',\n",
              " 'แต่วระแกกน',\n",
              " 'แล้วเมานน',\n",
              " 'เ้าเนะค',\n",
              " 'ใร่',\n",
              " 'แต่ว',\n",
              " 'เ็นักาา',\n",
              " 'าวย',\n",
              " 'ันี้ะ',\n",
              " 'ไมแที่แล',\n",
              " 'เาะ้อะไราย',\n",
              " 'นเ',\n",
              " 'เงารืมีแ',\n",
              " 'นะ',\n",
              " 'แต็นก',\n",
              " 'แลวเนี่มร',\n",
              " 'ะ',\n",
              " 'ยน',\n",
              " 'เาะวั่มานแนนก',\n",
              " 'าอย',\n",
              " 'าา',\n",
              " 'าเไมกน',\n",
              " 'ั',\n",
              " 'กเ',\n",
              " 'เนงค',\n",
              " 'แตกวะ',\n",
              " 'ะูค',\n",
              " 'แ่างเ',\n",
              " 'แลวากกาน',\n",
              " 'แล้วเ็มีอไิาง',\n",
              " 'แนน่',\n",
              " 'เ็นว',\n",
              " 'น',\n",
              " 'าินบ่อ',\n",
              " 'ะมี',\n",
              " 'กับอ',\n",
              " 'ไัวะ',\n",
              " 'ะน',\n",
              " 'แล้วค',\n",
              " 'เ่า',\n",
              " 'ะ',\n",
              " '่ะก',\n",
              " 'แลกยไมรร',\n",
              " '่ทกนก',\n",
              " 'ะราอา',\n",
              " '',\n",
              " 'ก',\n",
              " 'เาะวัยเก',\n",
              " 'นาย',\n",
              " 'าวอเนะน',\n",
              " 'นนเป็นอน',\n",
              " 'ที่ไ',\n",
              " '้า',\n",
              " 'มน',\n",
              " 'เ้ันเ',\n",
              " 'ใ่นกนางน',\n",
              " 'องะ',\n",
              " 'แล้ว้วยเรก',\n",
              " '',\n",
              " 'นวว้',\n",
              " 'เาะวปานก',\n",
              " 'งอง',\n",
              " 'งกน่',\n",
              " '้ยกนเะ',\n",
              " 'าก',\n",
              " 'บ',\n",
              " 'ี่ิ',\n",
              " '่ากก่องน',\n",
              " 'อรายคมน',\n",
              " 'แล้วกา',\n",
              " 'แต่วาง',\n",
              " 'เืรองม',\n",
              " 'เ้มคร',\n",
              " 'น',\n",
              " 'านก',\n",
              " 'วั',\n",
              " 'ร',\n",
              " 'เะวเมเ',\n",
              " 'วม้ว',\n",
              " '็ม',\n",
              " 'แลี',\n",
              " 'อวายเนน',\n",
              " 'เะวนั',\n",
              " 'นว่ารอ',\n",
              " 'แล้วา',\n",
              " 'นน',\n",
              " 'เาไนค',\n",
              " 'กา',\n",
              " 'เะวััน',\n",
              " 'เ่ออารน',\n",
              " 'แล้วรนน',\n",
              " '้',\n",
              " 'า',\n",
              " 'มัวะเาก',\n",
              " 'ืวักิ',\n",
              " 'าวันั้น',\n",
              " 'มาย่',\n",
              " 'มน',\n",
              " 'นมัาก',\n",
              " 'เอนน',\n",
              " 'เะัก',\n",
              " 'แล้ววัน',\n",
              " '',\n",
              " 'นกนเนี้ม',\n",
              " 'ไม',\n",
              " 'เย',\n",
              " 'แตวเ็บไใ',\n",
              " 'นอาน',\n",
              " 'เ่อื่อรค',\n",
              " '่านะ',\n",
              " 'ไมร',\n",
              " 'แล้วเ็กีกนไ',\n",
              " 'เ่ราที่มาก',\n",
              " 'ไม',\n",
              " 'กัิอ',\n",
              " 'เก็',\n",
              " 'งอไี',\n",
              " 'นั้รยไครับ',\n",
              " '',\n",
              " 'งเงเท',\n",
              " 'นนกนก',\n",
              " 'นอทา',\n",
              " 'ีก',\n",
              " 'กาเมืักัเน',\n",
              " 'เ็นาะ',\n",
              " 'ใะี่บเนี่',\n",
              " 'เีวแ',\n",
              " 'วเนรงนค',\n",
              " 'ะ',\n",
              " 'เ็นไะ',\n",
              " 'มก็น',\n",
              " 'อะไร่าง',\n",
              " 'กมกิ',\n",
              " 'ว',\n",
              " 'ไม',\n",
              " 'ง',\n",
              " 'แเ็นเ',\n",
              " 'ก',\n",
              " 'แกกน',\n",
              " 'เา',\n",
              " 'เ่น',\n",
              " 'แล้วไมาเ้',\n",
              " 'เ',\n",
              " 'น',\n",
              " 'แล้ว',\n",
              " 'เกนวังงน',\n",
              " 'แลาน',\n",
              " 'นกน',\n",
              " 'ก็',\n",
              " 'ใมากะค',\n",
              " 'นงเี',\n",
              " 'เะวัก',\n",
              " 'แตวน่ะ',\n",
              " 'แวรงคป',\n",
              " 'น่ค',\n",
              " 'ไ',\n",
              " 'นรงแา',\n",
              " '่',\n",
              " 'เ็นครอก',\n",
              " 'ะก้องมาคอน',\n",
              " 'ร่',\n",
              " 'ไม่',\n",
              " 'แตะม',\n",
              " 'า',\n",
              " 'แล้วงไานก',\n",
              " 'น่',\n",
              " 'แลอย',\n",
              " '',\n",
              " '',\n",
              " 'งเมื่อกา',\n",
              " 'อะ่าง',\n",
              " 'นนนเ',\n",
              " 'ะ',\n",
              " 'แต่วยน',\n",
              " 'เาะวาักคา',\n",
              " 'เาะวนาน',\n",
              " 'ไมวัป',\n",
              " 'ที่อกาน',\n",
              " 'มัแิ',\n",
              " 'เวนนงนร',\n",
              " '่าน',\n",
              " 'เะวัแ',\n",
              " 'นไก',\n",
              " '',\n",
              " 'เ',\n",
              " 'านัน',\n",
              " 'น',\n",
              " 'แ่ร',\n",
              " 'นคอรกน',\n",
              " 'เ็ววนน',\n",
              " 'เ็นเมกน',\n",
              " 'เ็น',\n",
              " 'แล้วน',\n",
              " 'แตว่าบ',\n",
              " '่านไ',\n",
              " 'แาัก',\n",
              " 'วน',\n",
              " 'เ้าแกไเนไย',\n",
              " '่าังเ',\n",
              " 'ไเว',\n",
              " 'น',\n",
              " 'งน่',\n",
              " 'น',\n",
              " '่',\n",
              " '้อง',\n",
              " 'นวนัร',\n",
              " 'อ่น',\n",
              " 'งน',\n",
              " 'เัอินเใ',\n",
              " 'ะา',\n",
              " 'นก',\n",
              " 'าน่',\n",
              " 'ใน',\n",
              " '',\n",
              " 'งไ',\n",
              " 'อเก',\n",
              " 'ก่นกทน',\n",
              " 'อน่ค',\n",
              " 'เ่อนี้',\n",
              " 'เ่นน',\n",
              " 'ีอนม',\n",
              " 'แลกวน',\n",
              " 'แลมา',\n",
              " 'ก็ม',\n",
              " 'เ',\n",
              " 'งยกน',\n",
              " 'กาก่ะเ',\n",
              " 'นู่น',\n",
              " 'แล้วรรค',\n",
              " 'งาย',\n",
              " 'น',\n",
              " 'เากัน',\n",
              " 'วรอม่ั',\n",
              " 'ใ้นเ',\n",
              " 'แล้วักไ',\n",
              " 'มั',\n",
              " 'นค',\n",
              " 'ในกา',\n",
              " 'อกก่าัง',\n",
              " '้',\n",
              " 'เัองา',\n",
              " 'แต่',\n",
              " 'น',\n",
              " 'นเ',\n",
              " 'แต่ไะ',\n",
              " 'าาแ',\n",
              " 'แล่ารับเเไ่',\n",
              " 'ไม่นกับ',\n",
              " 'มั่กเล',\n",
              " 'แต่้นเีนนก',\n",
              " 'มยครักัน',\n",
              " '',\n",
              " '',\n",
              " 'าย',\n",
              " 'เ่วง',\n",
              " 'างแ',\n",
              " '้ก่าน',\n",
              " 'เมนั่',\n",
              " 'แวาากอนนเ',\n",
              " 'เไอ']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eva_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "314\n",
            "314\n"
          ]
        }
      ],
      "source": [
        "print(len(eva_true))\n",
        "print(len(eva_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Char Error Rate: 0.828020037906062\n"
          ]
        }
      ],
      "source": [
        "eva = []\n",
        "for i in range(0, len(eva_true)):\n",
        "    error = cer(eva_true[i], eva_pred[i])\n",
        "    eva.append(error)\n",
        "# Print the result\n",
        "print(f\"Average Char Error Rate: {sum(eva) / len(eva)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# y_true = [string.decode('utf-8') for string in num_to_char(y_true).numpy()]\n",
        "# y_pred = [string.decode('utf-8') for string in num_to_char(top_one).numpy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "All arrays must be of the same length",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/somkiat/Lip_reading/model/LipNet.ipynb Cell 48\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Creating a DataFrame\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame({\u001b[39m'\u001b[39;49m\u001b[39my_true\u001b[39;49m\u001b[39m'\u001b[39;49m: y_true, \u001b[39m'\u001b[39;49m\u001b[39my_pred\u001b[39;49m\u001b[39m'\u001b[39;49m: y_pred})\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Display the DataFrame\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mhead(\u001b[39m29\u001b[39m))\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/pandas/core/frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    727\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[1;32m    728\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[1;32m    734\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[1;32m    735\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating a DataFrame\n",
        "df = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df.head(29))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# yhat = model.predict(sample[0])\n",
        "# for i in yhat:\n",
        "#     index = i[81]\n",
        "#     sorted_array = np.sort(index)[::-1]\n",
        "#     # Get the fifth largest value\n",
        "#     top_five_indices = np.argsort(index)[-5:]\n",
        "\n",
        "#     # Replace values not in the top five with 0\n",
        "#     result_array = np.where(np.isin(np.arange(len(index)), top_five_indices), index, 0)\n",
        "#     top_five_indices = np.argsort(result_array)[-5:]\n",
        "#     print(top_five_indices)\n",
        "#     result_array = np.zeros(max(top_five_indices) + 1)\n",
        "#     result_array[top_five_indices] = top_five_indices  # Y\n",
        "#     result_array = result_array[result_array != 0]\n",
        "#     for i in result_array:\n",
        "#         print(int(i))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# result_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# decoded = tf.keras.backend.ctc_decode(result_array, input_length=[200,200], greedy=True).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 56ms/step\n",
            "78\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n",
            "[\"ความเกิดจากนี้\", \"หรือบางทีดูชื่อเว็บไซต์อย่างเดียวไม่พอค่ะ\"]\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n",
            "[\"ะ\", \"\"]\n",
            "[46  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1]\n"
          ]
        }
      ],
      "source": [
        "# yhat = model.predict(sample[0])\n",
        "# print(np.argmax(yhat[0][0]))\n",
        "# print('~'*100, 'REAL TEXT')\n",
        "# tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]])\n",
        "# decoded = tf.keras.backend.ctc_decode(yhat, input_length=[200,200], greedy=True)[0][0].numpy()\n",
        "# print('~'*100, 'PREDICTIONS')\n",
        "# tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded])  \n",
        "# print(decoded[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #sample = test_data.next()\n",
        "# for sample in test_data:\n",
        "#     yhat = model.predict(sample[0])\n",
        "#     print('~'*100, 'REAL TEXT')\n",
        "#     tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]])\n",
        "#     decoded = tf.keras.backend.ctc_decode(yhat, input_length=[200,200], greedy=True)[0][0].numpy()\n",
        "#     print('~'*100, 'PREDICTIONS')\n",
        "#     tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded])    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea462999-f87e-4a7e-a057-5be7b6d8f7d5",
      "metadata": {
        "id": "ea462999-f87e-4a7e-a057-5be7b6d8f7d5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# print('~'*100, 'REAL TEXT')\n",
        "# tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82bd4c10-dd6e-411e-834b-2a3b43fd12c5",
      "metadata": {
        "id": "82bd4c10-dd6e-411e-834b-2a3b43fd12c5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d68ac46-c90b-4eab-a709-f19aee569ff5",
      "metadata": {
        "id": "5d68ac46-c90b-4eab-a709-f19aee569ff5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# print('~'*100, 'PREDICTIONS')\n",
        "# tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64622f98-e99b-4fed-a2cc-f0da82eb5431",
      "metadata": {
        "id": "64622f98-e99b-4fed-a2cc-f0da82eb5431",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "# Test on a Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8b0c4d0-2031-4331-b91d-d87b1ae6f6e2",
      "metadata": {
        "id": "a8b0c4d0-2031-4331-b91d-d87b1ae6f6e2"
      },
      "outputs": [],
      "source": [
        "#sample = load_data(tf.convert_to_tensor('.\\\\data\\\\s1\\\\bras9a.mpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cca60e4-47a9-4683-8a75-48f4684f723d",
      "metadata": {
        "id": "0cca60e4-47a9-4683-8a75-48f4684f723d"
      },
      "outputs": [],
      "source": [
        "# print('~'*100, 'REAL TEXT')\n",
        "# [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [sample[1]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc5037c-1e32-435c-b0cc-01e1fb3b863c",
      "metadata": {
        "id": "8cc5037c-1e32-435c-b0cc-01e1fb3b863c"
      },
      "outputs": [],
      "source": [
        "# yhat = model.predict(tf.expand_dims(sample[0], axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c4f77d-715d-409f-bc5e-3ebe48704e8f",
      "metadata": {
        "id": "22c4f77d-715d-409f-bc5e-3ebe48704e8f"
      },
      "outputs": [],
      "source": [
        "# decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4d12ecc-b634-499e-a4bc-db9f010835fb",
      "metadata": {
        "id": "e4d12ecc-b634-499e-a4bc-db9f010835fb"
      },
      "outputs": [],
      "source": [
        "# print('~'*100, 'PREDICTIONS')\n",
        "# [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58712ecc-5ac7-4c65-b341-7258aad68e28",
      "metadata": {
        "id": "58712ecc-5ac7-4c65-b341-7258aad68e28"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20a647bd-9a1b-4e6c-9f47-19ddb13c3dbf",
      "metadata": {
        "id": "20a647bd-9a1b-4e6c-9f47-19ddb13c3dbf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
