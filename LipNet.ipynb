{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a3573a47-3689-4668-b62f-5c8451b2b4e9",
      "metadata": {
        "id": "a3573a47-3689-4668-b62f-5c8451b2b4e9",
        "tags": []
      },
      "source": [
        "# 0. Install and Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b24af50c-20b8-409d-ad78-30a933fdd669",
      "metadata": {
        "id": "b24af50c-20b8-409d-ad78-30a933fdd669",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-25 09:52:17.959209: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-11-25 09:52:17.975828: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-25 09:52:17.975843: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-25 09:52:17.975858: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-25 09:52:17.979762: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from matplotlib import pyplot as plt\n",
        "# import imageio\n",
        "import dlib as dlib\n",
        "import sys\n",
        "from jiwer import cer\n",
        "# import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1e3db0b0-e559-4ad6-91fd-e7414b7d75e6",
      "metadata": {
        "id": "1e3db0b0-e559-4ad6-91fd-e7414b7d75e6",
        "outputId": "ac886b6c-4e04-4b29-8caa-54a6b1e56199"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-25 09:52:19.325706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-25 09:52:19.327925: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-25 09:52:19.328000: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "378d045a-3003-4f93-b7d2-a25a97774a68",
      "metadata": {
        "id": "378d045a-3003-4f93-b7d2-a25a97774a68",
        "tags": []
      },
      "outputs": [],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a19e88e-c7b9-45c1-ae1e-f2109329c71b",
      "metadata": {
        "id": "7a19e88e-c7b9-45c1-ae1e-f2109329c71b",
        "tags": []
      },
      "source": [
        "# 1. Build Data Loading Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "11ec4f5c-18c2-4f16-91b5-5eff5af9a39a",
      "metadata": {
        "id": "11ec4f5c-18c2-4f16-91b5-5eff5af9a39a"
      },
      "outputs": [],
      "source": [
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('/home/somkiat/Lip_reading/package/shape_predictor_68_face_landmarks.dat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ec735e0b-ec98-4eb0-8f49-c35527d6670a",
      "metadata": {
        "id": "ec735e0b-ec98-4eb0-8f49-c35527d6670a",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "77"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = [x for x in \"กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรลวศษสหฬอฮๆะาิีึืใไเแ่้็๊๋โฤ์ฯุูำั123456789\"]\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "be04e972-d7a5-4a72-82d8-a6bdde1f3ce6",
      "metadata": {
        "id": "be04e972-d7a5-4a72-82d8-a6bdde1f3ce6",
        "outputId": "43cd723b-d84a-4455-f317-a4ed2f677d71",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The vocabulary is: ['', 'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ล', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ๆ', 'ะ', 'า', 'ิ', 'ี', 'ึ', 'ื', 'ใ', 'ไ', 'เ', 'แ', '่', '้', '็', '๊', '๋', 'โ', 'ฤ', '์', 'ฯ', 'ุ', 'ู', 'ำ', 'ั', '1', '2', '3', '4', '5', '6', '7', '8', '9'] \n",
            "(size =78)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-25 09:52:28.012341: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-25 09:52:28.012446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-25 09:52:28.012500: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-25 09:52:28.047929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-25 09:52:28.048011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-25 09:52:28.048072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-25 09:52:28.048119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4907 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
          ]
        }
      ],
      "source": [
        "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, mask_token=None, oov_token=\"\")\n",
        "num_to_char = tf.keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), mask_token=None, oov_token=\"\", invert=True)\n",
        "\n",
        "print(f\"The vocabulary is: {char_to_num.get_vocabulary()} \")\n",
        "print(f\"(size ={char_to_num.vocabulary_size()})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8548cc59-6dfc-4acc-abc3-3e65212db02e",
      "metadata": {
        "id": "8548cc59-6dfc-4acc-abc3-3e65212db02e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def load_video(path):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "        ret, frame = cap.read()\n",
        "        frame_crop = frame\n",
        "        frame = tf.image.rgb_to_grayscale(frame)\n",
        "        frames.append(frame)\n",
        "        #frames.append(frame[y:y+h,x:x+w,:])\n",
        "\n",
        "    cap.release()\n",
        "    \n",
        "    mean = tf.math.reduce_mean(frames)\n",
        "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
        "    return tf.cast((frames - mean), tf.float32) / std\n",
        "\n",
        "\n",
        "def load_alignments(path):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "    tokens = []\n",
        "    for line in lines:\n",
        "        line = line.split()\n",
        "        if line[2] != 'sil':\n",
        "            tokens = [*tokens, line[2]]\n",
        "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[0:]\n",
        "\n",
        "\n",
        "def load_data(path: str):\n",
        "    path = bytes.decode(path.numpy())\n",
        "    path = path[::-1]\n",
        "    dot = path.index(\".\")\n",
        "    path = path[dot+1:]\n",
        "    path = path.split('/')[0]\n",
        "    file_name = path[::-1]\n",
        "\n",
        "    # video_path = os.path.join('/home','somkiat','Lip_reading','data','s1',f'{file_name}.mp4')\n",
        "    # alignment_path = os.path.join('/home','somkiat','Lip_reading','data','alignments','s1',f'{file_name}.align')\n",
        "    video_path = os.path.join('/home','somkiat','Lip_reading','data-20-11','s1',f'{file_name}.mp4')\n",
        "    alignment_path = os.path.join('/home','somkiat','Lip_reading','data-20-11','alignments','s1',f'{file_name}.align')\n",
        "\n",
        "\n",
        "    frames = load_video(video_path)\n",
        "    alignments = load_alignments(alignment_path)\n",
        "\n",
        "    return frames, alignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6871031a-b0ba-4c76-a852-f6329b0f2606",
      "metadata": {
        "id": "6871031a-b0ba-4c76-a852-f6329b0f2606",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def mappable_function(path:str) ->List[str]:\n",
        "    result = tf.py_function(load_data, [path],  (tf.float32, tf.int64))\n",
        "    if len(result[1]) > 78:\n",
        "        tf.print(path)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c40a7eb4-0c3e-4eab-9291-5611cb68ce08",
      "metadata": {
        "id": "c40a7eb4-0c3e-4eab-9291-5611cb68ce08",
        "tags": []
      },
      "source": [
        "# 2. Create Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f066fea2-91b1-42ed-a67d-00566a1a53ff",
      "metadata": {
        "id": "f066fea2-91b1-42ed-a67d-00566a1a53ff",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original data :  1319\n",
            "padded data :  659\n",
            "Length of train dataset: 500\n",
            "Length of test dataset: 159\n"
          ]
        }
      ],
      "source": [
        "# data = tf.data.Dataset.list_files('/home/somkiat/Lip_reading/data/s1/*.mp4')\n",
        "data = tf.data.Dataset.list_files(f'../data-20-11/s1/*.mp4')\n",
        "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
        "data = data.map(mappable_function)\n",
        "print('original data : ', (tf.data.experimental.cardinality(data).numpy()))\n",
        "# for batch in data:\n",
        "#     try:\n",
        "#         tensor1, tensor2 = batch\n",
        "#         if  tensor2.shape[0] > 78:\n",
        "#             print(tensor2.shape[0])\n",
        "#     except cv2.error as e:\n",
        "#         print(f\"OpenCV Error: {e}\")\n",
        "data = data.padded_batch(2, padded_shapes=([200,None, None,None],[79]), drop_remainder=True)\n",
        "print('padded data : ', (tf.data.experimental.cardinality(data).numpy()))\n",
        "data = data.prefetch(tf.data.AUTOTUNE)\n",
        "# Added for split train  & train\n",
        "train = data.take(500)\n",
        "#test = data.skip(100)\n",
        "test = data.skip(500)\n",
        "train_length = tf.data.experimental.cardinality(train).numpy()\n",
        "\n",
        "# Get the length of the `test` dataset\n",
        "test_length = tf.data.experimental.cardinality(test).numpy()\n",
        "\n",
        "print(\"Length of train dataset:\", train_length)\n",
        "print(\"Length of test dataset:\", test_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "424be4d4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of train dataset: 16000\n",
            "Length of test dataset: 2030\n"
          ]
        }
      ],
      "source": [
        "train_length = tf.data.experimental.cardinality(train).numpy()\n",
        "\n",
        "# Get the length of the `test` dataset\n",
        "test_length = tf.data.experimental.cardinality(test).numpy()\n",
        "\n",
        "print(\"Length of train dataset:\", train_length)\n",
        "print(\"Length of test dataset:\", test_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5281bde8-fdc8-4da1-bd55-5a7929a9e80c",
      "metadata": {
        "id": "5281bde8-fdc8-4da1-bd55-5a7929a9e80c",
        "outputId": "8a0ebaec-f1af-42ae-f987-91ff9f4125a1"
      },
      "outputs": [],
      "source": [
        "frames, alignments = data.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5cf2d676-93a9-434c-b3c7-bdcc2577b2e7",
      "metadata": {
        "id": "5cf2d676-93a9-434c-b3c7-bdcc2577b2e7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "test2 = data.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "efa6cd46-7079-46c0-b45b-832f339f6cb0",
      "metadata": {
        "id": "efa6cd46-7079-46c0-b45b-832f339f6cb0",
        "outputId": "c27b9c8a-52a0-42f2-cb60-73e3283e36e6",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]],\n",
              "\n",
              "         [[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]],\n",
              "\n",
              "         [[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]],\n",
              "\n",
              "         [[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]],\n",
              "\n",
              "         [[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]]],\n",
              "\n",
              "\n",
              "        [[[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]],\n",
              "\n",
              "         [[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]],\n",
              "\n",
              "         [[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]],\n",
              "\n",
              "         [[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]],\n",
              "\n",
              "         [[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]]],\n",
              "\n",
              "\n",
              "        [[[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]],\n",
              "\n",
              "         [[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]],\n",
              "\n",
              "         [[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]],\n",
              "\n",
              "         [[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]],\n",
              "\n",
              "         [[3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          ...,\n",
              "          [3.1386685],\n",
              "          [3.1386685],\n",
              "          [3.1386685]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]]],\n",
              "\n",
              "\n",
              "        [[[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]]],\n",
              "\n",
              "\n",
              "        [[[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]]]],\n",
              "\n",
              "\n",
              "\n",
              "       [[[[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]],\n",
              "\n",
              "         [[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]],\n",
              "\n",
              "         [[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]],\n",
              "\n",
              "         [[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]],\n",
              "\n",
              "         [[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]]],\n",
              "\n",
              "\n",
              "        [[[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]],\n",
              "\n",
              "         [[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]],\n",
              "\n",
              "         [[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]],\n",
              "\n",
              "         [[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]],\n",
              "\n",
              "         [[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]]],\n",
              "\n",
              "\n",
              "        [[[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]],\n",
              "\n",
              "         [[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]],\n",
              "\n",
              "         [[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]],\n",
              "\n",
              "         [[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]],\n",
              "\n",
              "         [[2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          ...,\n",
              "          [2.4518328],\n",
              "          [2.4518328],\n",
              "          [2.4518328]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]]],\n",
              "\n",
              "\n",
              "        [[[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]]],\n",
              "\n",
              "\n",
              "        [[[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]],\n",
              "\n",
              "         [[0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          ...,\n",
              "          [0.       ],\n",
              "          [0.       ],\n",
              "          [0.       ]]]]], dtype=float32)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val = test2.next(); val[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f68a44cd3a0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(val[0][0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f47733c-83bc-465c-b118-b198b492ad37",
      "metadata": {
        "id": "0f47733c-83bc-465c-b118-b198b492ad37",
        "tags": []
      },
      "source": [
        "# 3. Design the Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d8e9a497-191b-4842-afbd-26f5e13c43ba",
      "metadata": {
        "id": "d8e9a497-191b-4842-afbd-26f5e13c43ba",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3f753ed2-70b9-4236-8c1c-08ca065dc8bf",
      "metadata": {
        "id": "3f753ed2-70b9-4236-8c1c-08ca065dc8bf",
        "outputId": "aad3e779-f981-4327-e97a-995d2fed7941"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(200, 46, 140, 1)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.as_numpy_iterator().next()[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f9171056-a352-491a-9ed9-92b28ced268e",
      "metadata": {
        "id": "f9171056-a352-491a-9ed9-92b28ced268e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "#model.add(Conv3D(128, 3, input_shape=(75,,None,1), padding='same'))\n",
        "model.add(Conv3D(128, 3, input_shape=(200, 46, 140, 1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(256, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(200, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a99b31b7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 200, 46, 140, 12   3584      \n",
            "                             8)                                  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 200, 46, 140, 12   0         \n",
            "                             8)                                  \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3  (None, 200, 23, 70, 128   0         \n",
            " D)                          )                                   \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 200, 23, 70, 256   884992    \n",
            "                             )                                   \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 200, 23, 70, 256   0         \n",
            "                             )                                   \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPoolin  (None, 200, 11, 35, 256   0         \n",
            " g3D)                        )                                   \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 200, 11, 35, 200   1382600   \n",
            "                             )                                   \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 200, 11, 35, 200   0         \n",
            "                             )                                   \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPoolin  (None, 200, 5, 17, 200)   0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 200, 17000)        0         \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 200, 256)          17540096  \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 200, 256)          0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 200, 256)          394240    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 200, 256)          0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200, 79)           20303     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20225815 (77.16 MB)\n",
            "Trainable params: 20225815 (77.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 200, 46, 140, 1)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c2eae0-c359-41a4-97a0-75c44dccb7d1",
      "metadata": {
        "id": "e5c2eae0-c359-41a4-97a0-75c44dccb7d1",
        "outputId": "6221d1e1-4db8-4b8b-949e-13ebf22debf3",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-20 13:44:49.254067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
            "2023-11-20 13:44:49.360022: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        }
      ],
      "source": [
        "yhat = model.predict(val[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec02176-5c26-46c3-aff7-8352e6563c7d",
      "metadata": {
        "id": "2ec02176-5c26-46c3-aff7-8352e6563c7d",
        "tags": []
      },
      "source": [
        "# 4. Setup Training Options and Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ab015fd0-7fb4-4d5d-9fa2-30a05dbd515a",
      "metadata": {
        "id": "ab015fd0-7fb4-4d5d-9fa2-30a05dbd515a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def scheduler(epoch, lr):\n",
        "    if epoch < 30:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c564d5c9-db54-4e88-b311-9aeab7fb3e69",
      "metadata": {
        "id": "c564d5c9-db54-4e88-b311-9aeab7fb3e69",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def CTCLoss(y_true, y_pred):\n",
        "\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    #ignore_longer_outputs_than_inputs=True\n",
        "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04be90d8-2482-46f9-b513-d5f4f8001c7e",
      "metadata": {
        "id": "04be90d8-2482-46f9-b513-d5f4f8001c7e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=CTCLoss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eab49367-3f1e-4464-ae76-dbd07549d97e",
      "metadata": {
        "id": "eab49367-3f1e-4464-ae76-dbd07549d97e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#checkpoint_callback1 = ModelCheckpoint('/home/somkiat/Lip_reading/checkpoint_1/checkpoint.h5', monitor='loss')\n",
        "checkpoint_callback = ModelCheckpoint('/home/somkiat/Lip_reading/checkpoint_1/checkpoint', monitor='val_loss',save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e085a632-d464-46ef-8777-959cad4adb2c",
      "metadata": {
        "id": "e085a632-d464-46ef-8777-959cad4adb2c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "schedule_callback = LearningRateScheduler(scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "962acf3a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "class LossHistoryAndSave(keras.callbacks.Callback):\n",
        "    def __init__(self, file_path):\n",
        "        super().__init__()\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.file_path = file_path\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        \n",
        "        # Save loss values to a file\n",
        "        with open(self.file_path, 'a') as file:\n",
        "            file.write(f'Epoch {epoch + 1}: Training Loss: {logs.get(\"loss\")}, Validation Loss: {logs.get(\"val_loss\")}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed6fdd4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_file_path = '/home/somkiat/Lip_reading/loss_log/loss_history.txt'\n",
        "# Create an instance of the custom callback\n",
        "loss_history_and_save = LossHistoryAndSave(loss_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ad8392d",
      "metadata": {},
      "outputs": [],
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"/home/somkiat/Lip_reading/logs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ProduceExample(tf.keras.callbacks.Callback): \n",
        "    def __init__(self, dataset) -> None: \n",
        "        self.dataset = dataset.as_numpy_iterator()\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
        "        data = self.dataset.next()\n",
        "        yhat = self.model.predict(data[0])\n",
        "        decoded = tf.keras.backend.ctc_decode(yhat, [200,200], greedy=False)[0][0].numpy()\n",
        "        for x in range(len(yhat)):           \n",
        "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
        "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
        "            print('~'*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example_callback = ProduceExample(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e9bf98d-80f4-4320-b4c4-c0fae9f39500",
      "metadata": {
        "id": "4e9bf98d-80f4-4320-b4c4-c0fae9f39500",
        "outputId": "5d0254fc-3710-48d1-bce0-efdae4de8413",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16000/16000 [==============================] - ETA: 0s - loss: 105.0435"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-20 16:32:31.686843: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: FileNotFoundError: [Errno 2] No such file or directory: '/home/somkiat/Lip_reading/data/alignments/s1/290-ซึ่งพอออกมาแล้วเนี่ยนะคะ เหล่าพี่น้องของซุสเนี่ยก็ไม่ได้ออกมาเป็นเด็กแบเบาะนะคะ.align'\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/home/somkiat/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
            "    return func(device, token, args)\n",
            "\n",
            "  File \"/home/somkiat/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
            "    outputs = self._call(device, args)\n",
            "\n",
            "  File \"/home/somkiat/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
            "    ret = self._func(*args)\n",
            "\n",
            "  File \"/home/somkiat/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "\n",
            "  File \"/tmp/ipykernel_102178/593264020.py\", line 42, in load_data\n",
            "    alignments = load_alignments(alignment_path)\n",
            "\n",
            "  File \"/tmp/ipykernel_102178/593264020.py\", line 19, in load_alignments\n",
            "    with open(path, 'r', encoding='utf-8') as f:\n",
            "\n",
            "  File \"/home/somkiat/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 286, in _modified_open\n",
            "    return io_open(file, *args, **kwargs)\n",
            "\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/home/somkiat/Lip_reading/data/alignments/s1/290-ซึ่งพอออกมาแล้วเนี่ยนะคะ เหล่าพี่น้องของซุสเนี่ยก็ไม่ได้ออกมาเป็นเด็กแบเบาะนะคะ.align'\n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "UnknownError",
          "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} FileNotFoundError: [Errno 2] No such file or directory: '/home/somkiat/Lip_reading/data/alignments/s1/290-ซึ่งพอออกมาแล้วเนี่ยนะคะ เหล่าพี่น้องของซุสเนี่ยก็ไม่ได้ออกมาเป็นเด็กแบเบาะนะคะ.align'\nTraceback (most recent call last):\n\n  File \"/home/somkiat/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/home/somkiat/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/home/somkiat/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/home/somkiat/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/ipykernel_102178/593264020.py\", line 42, in load_data\n    alignments = load_alignments(alignment_path)\n\n  File \"/tmp/ipykernel_102178/593264020.py\", line 19, in load_alignments\n    with open(path, 'r', encoding='utf-8') as f:\n\n  File \"/home/somkiat/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 286, in _modified_open\n    return io_open(file, *args, **kwargs)\n\nFileNotFoundError: [Errno 2] No such file or directory: '/home/somkiat/Lip_reading/data/alignments/s1/290-ซึ่งพอออกมาแล้วเนี่ยนะคะ เหล่าพี่น้องของซุสเนี่ยก็ไม่ได้ออกมาเป็นเด็กแบเบาะนะคะ.align'\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/home/somkiat/Lip_reading/model/LipNet.ipynb Cell 37\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train, validation_data\u001b[39m=\u001b[39;49mtest, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[example_callback, early_stopping, tensorboard_callback, loss_history_and_save, checkpoint_callback, schedule_callback])\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "\u001b[1;32m/home/somkiat/Lip_reading/model/LipNet.ipynb Cell 37\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_epoch_end\u001b[39m(\u001b[39mself\u001b[39m, epoch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mnext()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     yhat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(data[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     decoded \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mctc_decode(yhat, [\u001b[39m200\u001b[39m,\u001b[39m200\u001b[39m], greedy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumpy()\n",
            "\u001b[0;31mUnknownError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} FileNotFoundError: [Errno 2] No such file or directory: '/home/somkiat/Lip_reading/data/alignments/s1/290-ซึ่งพอออกมาแล้วเนี่ยนะคะ เหล่าพี่น้องของซุสเนี่ยก็ไม่ได้ออกมาเป็นเด็กแบเบาะนะคะ.align'\nTraceback (most recent call last):\n\n  File \"/home/somkiat/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/home/somkiat/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/home/somkiat/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/home/somkiat/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/ipykernel_102178/593264020.py\", line 42, in load_data\n    alignments = load_alignments(alignment_path)\n\n  File \"/tmp/ipykernel_102178/593264020.py\", line 19, in load_alignments\n    with open(path, 'r', encoding='utf-8') as f:\n\n  File \"/home/somkiat/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 286, in _modified_open\n    return io_open(file, *args, **kwargs)\n\nFileNotFoundError: [Errno 2] No such file or directory: '/home/somkiat/Lip_reading/data/alignments/s1/290-ซึ่งพอออกมาแล้วเนี่ยนะคะ เหล่าพี่น้องของซุสเนี่ยก็ไม่ได้ออกมาเป็นเด็กแบเบาะนะคะ.align'\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: "
          ]
        }
      ],
      "source": [
        "model.fit(train, validation_data=test, epochs=100, batch_size=64, callbacks=[example_callback, early_stopping, tensorboard_callback, loss_history_and_save, checkpoint_callback, schedule_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa8ee94b-89f7-4733-8a0c-a86f86ff590a",
      "metadata": {
        "id": "fa8ee94b-89f7-4733-8a0c-a86f86ff590a",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "# 5. Make a Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01fa7204-ce0e-49a8-8dbd-14fe5dfead40",
      "metadata": {
        "id": "01fa7204-ce0e-49a8-8dbd-14fe5dfead40",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n",
        "#output = 'checkpoints.zip'\n",
        "#gdown.download(url, output, quiet=False)\n",
        "#gdown.extractall('checkpoints.zip', 'models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1681718b-1169-410c-933f-bd051da9b718",
      "metadata": {
        "id": "1681718b-1169-410c-933f-bd051da9b718"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.optimizers import legacy\n",
        "\n",
        "# # define your optimizer as a legacy optimizer\n",
        "# optimizer = legacy.Adam()\n",
        "\n",
        "# model.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "247f664d-3c87-4e96-946e-930dad0e1c2c",
      "metadata": {
        "id": "247f664d-3c87-4e96-946e-930dad0e1c2c",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f571c1645e0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model.load_weights('/home/somkiat/Lip_reading/checkpoint_1/checkpoint')\n",
        "model.load_weights(f'../data/checkpoint_1/checkpoint')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "38546dc2-bee9-4837-864b-8a884df40ad7",
      "metadata": {
        "id": "38546dc2-bee9-4837-864b-8a884df40ad7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "test_data = test.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a43621f0-229d-4c0d-9554-9c3a3da9c61a",
      "metadata": {
        "id": "a43621f0-229d-4c0d-9554-9c3a3da9c61a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "sample = test_data.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-25 10:01:11.677306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
            "2023-11-25 10:01:11.715210: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
            "2023-11-25 10:01:11.770591: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.770614: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.770626: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.770637: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.770649: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.772323: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.772340: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.780016: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.795722: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.795738: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:13.362744: W tensorflow/tsl/framework/bfc_allocator.cc:366] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n"
          ]
        }
      ],
      "source": [
        "eva_true = []\n",
        "eva_pred = []\n",
        "for sample in test_data:\n",
        "    try:\n",
        "        for i in range(0, 2):\n",
        "            y_true = []\n",
        "            for j in sample[1][i]:\n",
        "                if j != 0:\n",
        "                    y_true.append(j)\n",
        "            yhat = model.predict(sample[0])\n",
        "            eva_true.append(''.join([string.decode('utf-8') for string in num_to_char(y_true).numpy()]))                                                                                      \n",
        "            y_pred = []\n",
        "            for k in yhat[i]:\n",
        "                sorted_array = np.sort(k)[::-1]\n",
        "                # Get the fifth largest value\n",
        "                top_five_indices = np.argsort(k)[-5:]\n",
        "\n",
        "                # Replace values not in the top five with 0\n",
        "                result_array = np.where(np.isin(np.arange(len(k)), top_five_indices), k, 0)\n",
        "                top_five_indices = np.argsort(result_array)[-5:]\n",
        "                result_array = np.zeros(np.max(top_five_indices) + 1)\n",
        "                result_array[top_five_indices] = top_five_indices  # Y\n",
        "                result_array = result_array[result_array != 0]\n",
        "                top_five = []\n",
        "                for x in result_array:\n",
        "                    top_five.append(x)\n",
        "                y_pred.append(top_five)\n",
        "            top_one = []\n",
        "            for m in range(0, len(y_true)):\n",
        "                if y_true[m] in y_pred[m]:\n",
        "                    top_one.append(y_true[m])\n",
        "                else:\n",
        "                    # top_one.append(max)\n",
        "                    top_one.append(79)\n",
        "            eva_pred.append(''.join([string.decode('utf-8') for string in num_to_char(top_one).numpy()]))\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['แล้ว็นการัาน',\n",
              " 'แล้วเมงไกน',\n",
              " 'ใราน',\n",
              " 'นแา',\n",
              " 'ใ้น่อง',\n",
              " 'น้องเป็นแ',\n",
              " 'กรัะค',\n",
              " 'ะ่นาค',\n",
              " 'เาะวก็อคิ',\n",
              " 'แต่รายะัััง่',\n",
              " 'งมกา',\n",
              " 'น',\n",
              " 'งก',\n",
              " 'ัอยาน',\n",
              " 'แก้อนจั',\n",
              " 'แต่วรก',\n",
              " 'แั',\n",
              " 'แา',\n",
              " 'ี',\n",
              " 'เกิัน',\n",
              " 'ราร',\n",
              " 'กัก',\n",
              " 'เะกเอกกกนนกายริง',\n",
              " 'วมา',\n",
              " 'นทกันเย',\n",
              " 'เาั่มัน',\n",
              " 'ัใก้ม',\n",
              " 'นูน',\n",
              " 'ั่ัรเรื่อง',\n",
              " 'วใัเมน',\n",
              " '่ารก',\n",
              " '',\n",
              " '่เกมนงเนี่',\n",
              " 'าง',\n",
              " 'งงเป็นน',\n",
              " 'เล่ยแนั่',\n",
              " 'ไม่ระ',\n",
              " 'นะ',\n",
              " '็ก',\n",
              " '',\n",
              " 'เาะ้กน่า',\n",
              " 'เ่่อ่งไ',\n",
              " 'ร',\n",
              " 'ียนเ',\n",
              " 'ยาไ้ย',\n",
              " 'แตรวเร็',\n",
              " 'เ็นที่',\n",
              " 'น',\n",
              " 'กอะไร',\n",
              " 'ง',\n",
              " 'น่ค',\n",
              " 'แต่กนมั่ายบ',\n",
              " 'แล้วกว',\n",
              " 'นากเ',\n",
              " 'เีวาน',\n",
              " 'แต่วระแกกน',\n",
              " 'แล้วเมานน',\n",
              " 'เ้าเนะค',\n",
              " 'ใร่',\n",
              " 'แต่ว',\n",
              " 'เ็นักาา',\n",
              " 'าวย',\n",
              " 'ันี้ะ',\n",
              " 'ไมแที่แล',\n",
              " 'เาะ้อะไราย',\n",
              " 'นเ',\n",
              " 'เงารืมีแ',\n",
              " 'นะ',\n",
              " 'แต็นก',\n",
              " 'แลวเนี่มร',\n",
              " 'ะ',\n",
              " 'ยน',\n",
              " 'เาะวั่มานแนนก',\n",
              " 'าอย',\n",
              " 'าา',\n",
              " 'าเไมกน',\n",
              " 'ั',\n",
              " 'กเ',\n",
              " 'เนงค',\n",
              " 'แตกวะ',\n",
              " 'ะูค',\n",
              " 'แ่างเ',\n",
              " 'แลวากกาน',\n",
              " 'แล้วเ็มีอไิาง',\n",
              " 'แนน่',\n",
              " 'เ็นว',\n",
              " 'น',\n",
              " 'าินบ่อ',\n",
              " 'ะมี',\n",
              " 'กับอ',\n",
              " 'ไัวะ',\n",
              " 'ะน',\n",
              " 'แล้วค',\n",
              " 'เ่า',\n",
              " 'ะ',\n",
              " '่ะก',\n",
              " 'แลกยไมรร',\n",
              " '่ทกนก',\n",
              " 'ะราอา',\n",
              " '',\n",
              " 'ก',\n",
              " 'เาะวัยเก',\n",
              " 'นาย',\n",
              " 'าวอเนะน',\n",
              " 'นนเป็นอน',\n",
              " 'ที่ไ',\n",
              " '้า',\n",
              " 'มน',\n",
              " 'เ้ันเ',\n",
              " 'ใ่นกนางน',\n",
              " 'องะ',\n",
              " 'แล้ว้วยเรก',\n",
              " '',\n",
              " 'นวว้',\n",
              " 'เาะวปานก',\n",
              " 'งอง',\n",
              " 'งกน่',\n",
              " '้ยกนเะ',\n",
              " 'าก',\n",
              " 'บ',\n",
              " 'ี่ิ',\n",
              " '่ากก่องน',\n",
              " 'อรายคมน',\n",
              " 'แล้วกา',\n",
              " 'แต่วาง',\n",
              " 'เืรองม',\n",
              " 'เ้มคร',\n",
              " 'น',\n",
              " 'านก',\n",
              " 'วั',\n",
              " 'ร',\n",
              " 'เะวเมเ',\n",
              " 'วม้ว',\n",
              " '็ม',\n",
              " 'แลี',\n",
              " 'อวายเนน',\n",
              " 'เะวนั',\n",
              " 'นว่ารอ',\n",
              " 'แล้วา',\n",
              " 'นน',\n",
              " 'เาไนค',\n",
              " 'กา',\n",
              " 'เะวััน',\n",
              " 'เ่ออารน',\n",
              " 'แล้วรนน',\n",
              " '้',\n",
              " 'า',\n",
              " 'มัวะเาก',\n",
              " 'ืวักิ',\n",
              " 'าวันั้น',\n",
              " 'มาย่',\n",
              " 'มน',\n",
              " 'นมัาก',\n",
              " 'เอนน',\n",
              " 'เะัก',\n",
              " 'แล้ววัน',\n",
              " '',\n",
              " 'นกนเนี้ม',\n",
              " 'ไม',\n",
              " 'เย',\n",
              " 'แตวเ็บไใ',\n",
              " 'นอาน',\n",
              " 'เ่อื่อรค',\n",
              " '่านะ',\n",
              " 'ไมร',\n",
              " 'แล้วเ็กีกนไ',\n",
              " 'เ่ราที่มาก',\n",
              " 'ไม',\n",
              " 'กัิอ',\n",
              " 'เก็',\n",
              " 'งอไี',\n",
              " 'นั้รยไครับ',\n",
              " '',\n",
              " 'งเงเท',\n",
              " 'นนกนก',\n",
              " 'นอทา',\n",
              " 'ีก',\n",
              " 'กาเมืักัเน',\n",
              " 'เ็นาะ',\n",
              " 'ใะี่บเนี่',\n",
              " 'เีวแ',\n",
              " 'วเนรงนค',\n",
              " 'ะ',\n",
              " 'เ็นไะ',\n",
              " 'มก็น',\n",
              " 'อะไร่าง',\n",
              " 'กมกิ',\n",
              " 'ว',\n",
              " 'ไม',\n",
              " 'ง',\n",
              " 'แเ็นเ',\n",
              " 'ก',\n",
              " 'แกกน',\n",
              " 'เา',\n",
              " 'เ่น',\n",
              " 'แล้วไมาเ้',\n",
              " 'เ',\n",
              " 'น',\n",
              " 'แล้ว',\n",
              " 'เกนวังงน',\n",
              " 'แลาน',\n",
              " 'นกน',\n",
              " 'ก็',\n",
              " 'ใมากะค',\n",
              " 'นงเี',\n",
              " 'เะวัก',\n",
              " 'แตวน่ะ',\n",
              " 'แวรงคป',\n",
              " 'น่ค',\n",
              " 'ไ',\n",
              " 'นรงแา',\n",
              " '่',\n",
              " 'เ็นครอก',\n",
              " 'ะก้องมาคอน',\n",
              " 'ร่',\n",
              " 'ไม่',\n",
              " 'แตะม',\n",
              " 'า',\n",
              " 'แล้วงไานก',\n",
              " 'น่',\n",
              " 'แลอย',\n",
              " '',\n",
              " '',\n",
              " 'งเมื่อกา',\n",
              " 'อะ่าง',\n",
              " 'นนนเ',\n",
              " 'ะ',\n",
              " 'แต่วยน',\n",
              " 'เาะวาักคา',\n",
              " 'เาะวนาน',\n",
              " 'ไมวัป',\n",
              " 'ที่อกาน',\n",
              " 'มัแิ',\n",
              " 'เวนนงนร',\n",
              " '่าน',\n",
              " 'เะวัแ',\n",
              " 'นไก',\n",
              " '',\n",
              " 'เ',\n",
              " 'านัน',\n",
              " 'น',\n",
              " 'แ่ร',\n",
              " 'นคอรกน',\n",
              " 'เ็ววนน',\n",
              " 'เ็นเมกน',\n",
              " 'เ็น',\n",
              " 'แล้วน',\n",
              " 'แตว่าบ',\n",
              " '่านไ',\n",
              " 'แาัก',\n",
              " 'วน',\n",
              " 'เ้าแกไเนไย',\n",
              " '่าังเ',\n",
              " 'ไเว',\n",
              " 'น',\n",
              " 'งน่',\n",
              " 'น',\n",
              " '่',\n",
              " '้อง',\n",
              " 'นวนัร',\n",
              " 'อ่น',\n",
              " 'งน',\n",
              " 'เัอินเใ',\n",
              " 'ะา',\n",
              " 'นก',\n",
              " 'าน่',\n",
              " 'ใน',\n",
              " '',\n",
              " 'งไ',\n",
              " 'อเก',\n",
              " 'ก่นกทน',\n",
              " 'อน่ค',\n",
              " 'เ่อนี้',\n",
              " 'เ่นน',\n",
              " 'ีอนม',\n",
              " 'แลกวน',\n",
              " 'แลมา',\n",
              " 'ก็ม',\n",
              " 'เ',\n",
              " 'งยกน',\n",
              " 'กาก่ะเ',\n",
              " 'นู่น',\n",
              " 'แล้วรรค',\n",
              " 'งาย',\n",
              " 'น',\n",
              " 'เากัน',\n",
              " 'วรอม่ั',\n",
              " 'ใ้นเ',\n",
              " 'แล้วักไ',\n",
              " 'มั',\n",
              " 'นค',\n",
              " 'ในกา',\n",
              " 'อกก่าัง',\n",
              " '้',\n",
              " 'เัองา',\n",
              " 'แต่',\n",
              " 'น',\n",
              " 'นเ',\n",
              " 'แต่ไะ',\n",
              " 'าาแ',\n",
              " 'แล่ารับเเไ่',\n",
              " 'ไม่นกับ',\n",
              " 'มั่กเล',\n",
              " 'แต่้นเีนนก',\n",
              " 'มยครักัน',\n",
              " '',\n",
              " '',\n",
              " 'าย',\n",
              " 'เ่วง',\n",
              " 'างแ',\n",
              " '้ก่าน',\n",
              " 'เมนั่',\n",
              " 'แวาากอนนเ',\n",
              " 'เไอ']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eva_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "314\n",
            "314\n"
          ]
        }
      ],
      "source": [
        "print(len(eva_true))\n",
        "print(len(eva_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Char Error Rate: 0.828020037906062\n"
          ]
        }
      ],
      "source": [
        "eva = []\n",
        "for i in range(0, len(eva_true)):\n",
        "    error = cer(eva_true[i], eva_pred[i])\n",
        "    eva.append(error)\n",
        "# Print the result\n",
        "print(f\"Average Char Error Rate: {sum(eva) / len(eva)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# y_true = [string.decode('utf-8') for string in num_to_char(y_true).numpy()]\n",
        "# y_pred = [string.decode('utf-8') for string in num_to_char(top_one).numpy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "All arrays must be of the same length",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/somkiat/Lip_reading/model/LipNet.ipynb Cell 48\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Creating a DataFrame\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame({\u001b[39m'\u001b[39;49m\u001b[39my_true\u001b[39;49m\u001b[39m'\u001b[39;49m: y_true, \u001b[39m'\u001b[39;49m\u001b[39my_pred\u001b[39;49m\u001b[39m'\u001b[39;49m: y_pred})\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Display the DataFrame\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mhead(\u001b[39m29\u001b[39m))\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/pandas/core/frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    727\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[1;32m    728\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[1;32m    734\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[1;32m    735\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating a DataFrame\n",
        "df = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df.head(29))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# yhat = model.predict(sample[0])\n",
        "# for i in yhat:\n",
        "#     index = i[81]\n",
        "#     sorted_array = np.sort(index)[::-1]\n",
        "#     # Get the fifth largest value\n",
        "#     top_five_indices = np.argsort(index)[-5:]\n",
        "\n",
        "#     # Replace values not in the top five with 0\n",
        "#     result_array = np.where(np.isin(np.arange(len(index)), top_five_indices), index, 0)\n",
        "#     top_five_indices = np.argsort(result_array)[-5:]\n",
        "#     print(top_five_indices)\n",
        "#     result_array = np.zeros(max(top_five_indices) + 1)\n",
        "#     result_array[top_five_indices] = top_five_indices  # Y\n",
        "#     result_array = result_array[result_array != 0]\n",
        "#     for i in result_array:\n",
        "#         print(int(i))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# result_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# decoded = tf.keras.backend.ctc_decode(result_array, input_length=[200,200], greedy=True).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 56ms/step\n",
            "78\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n",
            "[\"ความเกิดจากนี้\", \"หรือบางทีดูชื่อเว็บไซต์อย่างเดียวไม่พอค่ะ\"]\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n",
            "[\"ะ\", \"\"]\n",
            "[46  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1]\n"
          ]
        }
      ],
      "source": [
        "# yhat = model.predict(sample[0])\n",
        "# print(np.argmax(yhat[0][0]))\n",
        "# print('~'*100, 'REAL TEXT')\n",
        "# tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]])\n",
        "# decoded = tf.keras.backend.ctc_decode(yhat, input_length=[200,200], greedy=True)[0][0].numpy()\n",
        "# print('~'*100, 'PREDICTIONS')\n",
        "# tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded])  \n",
        "# print(decoded[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #sample = test_data.next()\n",
        "# for sample in test_data:\n",
        "#     yhat = model.predict(sample[0])\n",
        "#     print('~'*100, 'REAL TEXT')\n",
        "#     tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]])\n",
        "#     decoded = tf.keras.backend.ctc_decode(yhat, input_length=[200,200], greedy=True)[0][0].numpy()\n",
        "#     print('~'*100, 'PREDICTIONS')\n",
        "#     tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded])    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea462999-f87e-4a7e-a057-5be7b6d8f7d5",
      "metadata": {
        "id": "ea462999-f87e-4a7e-a057-5be7b6d8f7d5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# print('~'*100, 'REAL TEXT')\n",
        "# tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82bd4c10-dd6e-411e-834b-2a3b43fd12c5",
      "metadata": {
        "id": "82bd4c10-dd6e-411e-834b-2a3b43fd12c5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d68ac46-c90b-4eab-a709-f19aee569ff5",
      "metadata": {
        "id": "5d68ac46-c90b-4eab-a709-f19aee569ff5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# print('~'*100, 'PREDICTIONS')\n",
        "# tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64622f98-e99b-4fed-a2cc-f0da82eb5431",
      "metadata": {
        "id": "64622f98-e99b-4fed-a2cc-f0da82eb5431",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "# Test on a Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8b0c4d0-2031-4331-b91d-d87b1ae6f6e2",
      "metadata": {
        "id": "a8b0c4d0-2031-4331-b91d-d87b1ae6f6e2"
      },
      "outputs": [],
      "source": [
        "#sample = load_data(tf.convert_to_tensor('.\\\\data\\\\s1\\\\bras9a.mpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cca60e4-47a9-4683-8a75-48f4684f723d",
      "metadata": {
        "id": "0cca60e4-47a9-4683-8a75-48f4684f723d"
      },
      "outputs": [],
      "source": [
        "# print('~'*100, 'REAL TEXT')\n",
        "# [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [sample[1]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc5037c-1e32-435c-b0cc-01e1fb3b863c",
      "metadata": {
        "id": "8cc5037c-1e32-435c-b0cc-01e1fb3b863c"
      },
      "outputs": [],
      "source": [
        "# yhat = model.predict(tf.expand_dims(sample[0], axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c4f77d-715d-409f-bc5e-3ebe48704e8f",
      "metadata": {
        "id": "22c4f77d-715d-409f-bc5e-3ebe48704e8f"
      },
      "outputs": [],
      "source": [
        "# decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4d12ecc-b634-499e-a4bc-db9f010835fb",
      "metadata": {
        "id": "e4d12ecc-b634-499e-a4bc-db9f010835fb"
      },
      "outputs": [],
      "source": [
        "# print('~'*100, 'PREDICTIONS')\n",
        "# [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58712ecc-5ac7-4c65-b341-7258aad68e28",
      "metadata": {
        "id": "58712ecc-5ac7-4c65-b341-7258aad68e28"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20a647bd-9a1b-4e6c-9f47-19ddb13c3dbf",
      "metadata": {
        "id": "20a647bd-9a1b-4e6c-9f47-19ddb13c3dbf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
