{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a3573a47-3689-4668-b62f-5c8451b2b4e9",
      "metadata": {
        "id": "a3573a47-3689-4668-b62f-5c8451b2b4e9",
        "tags": []
      },
      "source": [
        "# 0. Install and Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b24af50c-20b8-409d-ad78-30a933fdd669",
      "metadata": {
        "id": "b24af50c-20b8-409d-ad78-30a933fdd669",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-03 10:48:05.542096: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-02-03 10:48:05.557712: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-03 10:48:05.557725: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-03 10:48:05.557736: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-03 10:48:05.560975: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import cv2\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c7b6d7a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "floder = \"..\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a19e88e-c7b9-45c1-ae1e-f2109329c71b",
      "metadata": {
        "id": "7a19e88e-c7b9-45c1-ae1e-f2109329c71b",
        "tags": []
      },
      "source": [
        "# 1. Build Data Loading Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ec735e0b-ec98-4eb0-8f49-c35527d6670a",
      "metadata": {
        "id": "ec735e0b-ec98-4eb0-8f49-c35527d6670a",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-03 10:48:06.285403: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
            "2024-02-03 10:48:06.285430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: lab-4090-B\n",
            "2024-02-03 10:48:06.285436: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: lab-4090-B\n",
            "2024-02-03 10:48:06.285490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.154.5\n",
            "2024-02-03 10:48:06.285505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.129.3\n",
            "2024-02-03 10:48:06.285508: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:312] kernel version 535.129.3 does not match DSO version 535.154.5 -- cannot find working devices in this configuration\n"
          ]
        }
      ],
      "source": [
        "vocab = [x for x in \"กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรลวศษสหฬอฮๆะาิีึืใไเแ่้็๊๋โฤ์ฯุูำั123456789\"] #define \n",
        "\n",
        "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, mask_token=None, oov_token=\"\")\n",
        "num_to_char = tf.keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), mask_token=None, oov_token=\"\", invert=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8548cc59-6dfc-4acc-abc3-3e65212db02e",
      "metadata": {
        "id": "8548cc59-6dfc-4acc-abc3-3e65212db02e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def load_video(path: str):\n",
        "    \"\"\"convert video to list of frame\n",
        "    path : path of video \"\"\"\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "        ret, frame = cap.read()\n",
        "        frame = tf.image.rgb_to_grayscale(frame)\n",
        "        frames.append(frame)\n",
        "\n",
        "    cap.release()\n",
        "    \n",
        "    mean = tf.math.reduce_mean(frames)\n",
        "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
        "    return tf.cast((frames - mean), tf.float32) / std #nomalization\n",
        "\n",
        "def load_alignments(path: str):\n",
        "    \"\"\"load data alignments in format text files alignment\n",
        "    path : path of alignments\"\"\"\n",
        "    \n",
        "    path = path.split('/')[-1]\n",
        "    path = path.split('-', 1)[-1]\n",
        "    path = path[::-1].split('.', 1)[-1]\n",
        "    file_name = path[::-1]\n",
        "    return char_to_num(tf.reshape(tf.strings.unicode_split(file_name, input_encoding='UTF-8'), (-1)))\n",
        "# def load_alignments(path: str):\n",
        "#     \"\"\"load data alignments in format text files alignment\n",
        "#     path : path of alignments\n",
        "#     file fomat  0 0 sil \n",
        "#                 0 20418 กระบวน \n",
        "#                 ...\n",
        "#                 128727 352800 sil\n",
        "#     \"\"\"\n",
        "#     with open(path, 'r', encoding='utf-8') as f:\n",
        "#         lines = f.readlines()\n",
        "#     tokens = []\n",
        "#     for line in lines:\n",
        "#         line = line.split() # covert string space to list\n",
        "#         if line[2] != 'sil':\n",
        "#             tokens = [*tokens, line[2]]\n",
        "#     print(tokens)\n",
        "#     return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))\n",
        "\n",
        "\n",
        "def load_data(path: str):\n",
        "    \"\"\"load data to convert video and download file alignment\"\"\"\n",
        "    path = bytes.decode(path.numpy())\n",
        "    \n",
        "    videonum = path.split('/')[-2]\n",
        "\n",
        "    path = path.split('/')[-1]\n",
        "    path = path[::-1].split('.', 1)[-1]\n",
        "    file_name = path[::-1]\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    video_path = f'{floder}/data/s1/{videonum}/{file_name}.mp4'\n",
        "    alignment_path = f'{floder}/data/alignments/{videonum}/word-level/{file_name}.align'\n",
        "\n",
        "\n",
        "    frames = load_video(video_path)\n",
        "    alignments = load_alignments(alignment_path)\n",
        "\n",
        "    if len(alignments) > 78:\n",
        "        os.remove(video_path)\n",
        "    return frames, alignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6871031a-b0ba-4c76-a852-f6329b0f2606",
      "metadata": {
        "id": "6871031a-b0ba-4c76-a852-f6329b0f2606",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def mappable_function(path:str) ->List[str]:\n",
        "    \"\"\"map data video and alignments file\n",
        "    path : path of alignment or video\"\"\"\n",
        "    result = tf.py_function(load_data, [path],  (tf.float32, tf.int64))\n",
        "    \n",
        "    if len(result[1]) > 78:\n",
        "        tf.print(path)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c40a7eb4-0c3e-4eab-9291-5611cb68ce08",
      "metadata": {
        "id": "c40a7eb4-0c3e-4eab-9291-5611cb68ce08",
        "tags": []
      },
      "source": [
        "# 2. Create Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f066fea2-91b1-42ed-a67d-00566a1a53ff",
      "metadata": {
        "id": "f066fea2-91b1-42ed-a67d-00566a1a53ff",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original data :  58211\n",
            "Length of train dataset: 26000\n",
            "Length of test dataset: 3105\n"
          ]
        }
      ],
      "source": [
        "data = tf.data.Dataset.list_files(f'{floder}/data/s1/*/*.mp4')\n",
        "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
        "data = data.map(mappable_function)\n",
        "print('original data : ', (tf.data.experimental.cardinality(data).numpy()))\n",
        "for batch in data:\n",
        "    try:\n",
        "        tensor1, tensor2 = batch\n",
        "        if  tensor2.shape[0] > 78:\n",
        "            print(tensor2.shape[0])\n",
        "    except cv2.error as e:\n",
        "        print(f\"OpenCV Error: {e}\")\n",
        "data = data.padded_batch(2, padded_shapes=([200,None, None,None],[79]), drop_remainder=True)\n",
        "# print('padded data : ', (tf.data.experimental.cardinality(data).numpy()))\n",
        "data = data.prefetch(tf.data.AUTOTUNE)\n",
        "# Added for split train  & train\n",
        "train = data.take(26000)\n",
        "#test = data.skip(100)\n",
        "test = data.skip(26000)\n",
        "train_length = tf.data.experimental.cardinality(train).numpy()\n",
        "\n",
        "# Get the length of the `test` dataset\n",
        "test_length = tf.data.experimental.cardinality(test).numpy()\n",
        "\n",
        "print(\"Length of train dataset:\", train_length)\n",
        "print(\"Length of test dataset:\", test_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7c7dd886",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "listdir = [\"../data/s1/video-6351/247- ป่านนี้แล้ว เจ้ายังคิดเรื่องที่ต้องชดใช้ความผิดที่ทำให้ขาของข้าพิการอยู่อีกหรือ .mp4\",\n",
        "           \"../data/s1/video-31323/50-คือเหมือนเดิมเหมือนกับกรณีของกูชาร์จเลย ก็คือต้องนำผู้ป่วยที่โดนต่อยเนี่ยออกมา  .mp4\",\n",
        "           \"../data/s1/video-26219/32-มากขึ้นนะครับแม่เป็นแบบนี้นะก็ก็เราเป็น ไอเดียดูนะครับก็ไม่ได้บอกว่าของผมมันถูก  .mp4\",\n",
        "           \"../data/s1/video-26219/3-อิสรภาพทางการเงินมากมันคือการมีรายได้ จากทรัพย์สินคือค่าเช่าดอกเบี้ยเงินปันผล  .mp4\",\n",
        "           \"../data/s1/video-41540/249-คุณจะต้องรู้ว่าพลังงานของคุณ ไม่เลือกใช้น้ำตาลกับแป้ง ก็ใช้ของมัน ของทอด ถูกไหม.mp4\",\n",
        "           \"../data/s1/video-41978/16-หุ้นแต่ละแบบมันมีข้อแตกต่างกันค่อนข้างเยอะนะครับอยู่ที่ว่าสไตล์เราจะเป็นสไตล์ไหน.mp4\",\n",
        "           \"../data/s1/video-29701/33-ก็ถูกปิดตายทางเดินแล้วก็ทิ้งไว้ในท้องอยู่เฉยเฉยเลยนะคะตัวกระเพาะน้อยที่เหลืออยู่.mp4\",\n",
        "           \"../data/s1/video-17327/156-เตรียมความพร้อมเรื่องด้านจิตใจมาละกันเพราะว่าเรามาอยู่กรุงเทพฯ เราตัวคนเดียวใช่ไหม.mp4\",\n",
        "           \"../data/s1/video-41518/249-คุณจะต้องรู้ว่าพลังงานของคุณ ไม่เลือกใช้น้ำตาลกับแป้ง ก็ใช้ของมัน ของทอด ถูกไหม.mp4\",\n",
        "           \"../data/s1/video-31323/49-คงชนะไม่ได้ใช้ช่วยแล้วนี้วิธีการต่อไปนะ ก็คือวิธีการดูแลผู้ป่วยเบื้องต้นนั้นก็  .mp4\",\n",
        "           \"../data/s1/video-23317/10-การดูถูกของคนไซปรัสต่อคนเอเชียอย่างเรา แม่บ้านไซปรัสยังไม่ได้เห็นด้วยตัวเองนะ คะ  .mp4\",\n",
        "           \"../data/s1/video-15213/273-แต่ถ้าสมมติว่าเราไปสังเกตภาษาอังกฤษที่วิวขึ้นให้ดูหรือว่าที่วิวพยายามตีความให้ดู.mp4\",\n",
        "           \"../data/s1/video-41521/42-เพราะฉะนั้น ระหว่างทาง ถ้าคุณไม่ได้เอาน้ําตาลไปเก็บเป็นไขมัน คุณจะเป็นเบาหวานเลย.mp4\",\n",
        "           \"../data/s1/video-40614/200-พระอาทิตย์กลัวจะมีปัญหานะคะ ก็เลยตัดสินใจว่าเออชุบชีวิตหนุมานขึ้นมาคุยกันดีกว่า.mp4\",\n",
        "           \"../data/s1/video-41541/42-เพราะฉะนั้น ระหว่างทาง ถ้าคุณไม่ได้เอาน้ําตาลไปเก็บเป็นไขมัน คุณจะเป็นเบาหวานเลย.mp4\",\n",
        "           \"../data/s1/video-266/26-ก็จะเห็นว่าเทคโนโลยีด้านเวลา ด้านอะไรเนี่ยก็จะเกี่ยวพันกับการเดินเรือเช่นกันค่ะ.mp4\",\"../data/s1/video-20714/190-ห้าเล่มเนี้ยถือว่าเยอะมากมากนะครับ เพราะจริงจริงเล่มหนึ่งมันก็หลายตังค์อยู่นะฮะ.mp4\"]\n",
        "for i in listdir:\n",
        "    try:\n",
        "        os.remove(i)\n",
        "    except:\n",
        "        print(\"h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "424be4d4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of train dataset: 26000\n",
            "Length of test dataset: 3114\n"
          ]
        }
      ],
      "source": [
        "train_length = tf.data.experimental.cardinality(train).numpy()\n",
        "\n",
        "# Get the length of the `test` dataset\n",
        "test_length = tf.data.experimental.cardinality(test).numpy()\n",
        "\n",
        "print(\"Length of train dataset:\", train_length)\n",
        "print(\"Length of test dataset:\", test_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5cf2d676-93a9-434c-b3c7-bdcc2577b2e7",
      "metadata": {
        "id": "5cf2d676-93a9-434c-b3c7-bdcc2577b2e7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "test2 = data.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "efa6cd46-7079-46c0-b45b-832f339f6cb0",
      "metadata": {
        "id": "efa6cd46-7079-46c0-b45b-832f339f6cb0",
        "outputId": "c27b9c8a-52a0-42f2-cb60-73e3283e36e6",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[37, 68, 25, 25, 68, 57, 25, 25, 47,  7, 30, 48, 33,  1, 58, 54,\n",
              "        36, 34, 61, 20, 25,  2, 65, 25, 10, 57, 47,  7,  2, 56, 33,  2,\n",
              "        51, 25,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [53, 43,  1, 47, 35, 54,  8, 47, 46,  0, 36,  7, 53, 27, 33, 68,\n",
              "        25,  4, 51, 43, 43, 46, 53, 35,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val = test2.next(); val[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f47733c-83bc-465c-b118-b198b492ad37",
      "metadata": {
        "id": "0f47733c-83bc-465c-b118-b198b492ad37",
        "tags": []
      },
      "source": [
        "# 3. Design the Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "d8e9a497-191b-4842-afbd-26f5e13c43ba",
      "metadata": {
        "id": "d8e9a497-191b-4842-afbd-26f5e13c43ba",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f9171056-a352-491a-9ed9-92b28ced268e",
      "metadata": {
        "id": "f9171056-a352-491a-9ed9-92b28ced268e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# designing model\n",
        "model = Sequential()\n",
        "#model.add(Conv3D(128, 3, input_shape=(75,,None,1), padding='same'))\n",
        "model.add(Conv3D(128, 3, input_shape=(200, 46, 140, 1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(256, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(200, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "3e30468d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 200, 46, 140, 1)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "ef75eafc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 200, 46, 140, 12   3584      \n",
            "                             8)                                  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 200, 46, 140, 12   0         \n",
            "                             8)                                  \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3  (None, 200, 23, 70, 128   0         \n",
            " D)                          )                                   \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 200, 23, 70, 256   884992    \n",
            "                             )                                   \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 200, 23, 70, 256   0         \n",
            "                             )                                   \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPoolin  (None, 200, 11, 35, 256   0         \n",
            " g3D)                        )                                   \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 200, 11, 35, 200   1382600   \n",
            "                             )                                   \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 200, 11, 35, 200   0         \n",
            "                             )                                   \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPoolin  (None, 200, 5, 17, 200)   0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 200, 17000)        0         \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 200, 256)          17540096  \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 200, 256)          0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 200, 256)          394240    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 200, 256)          0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200, 79)           20303     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20225815 (77.16 MB)\n",
            "Trainable params: 20225815 (77.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec02176-5c26-46c3-aff7-8352e6563c7d",
      "metadata": {
        "id": "2ec02176-5c26-46c3-aff7-8352e6563c7d",
        "tags": []
      },
      "source": [
        "# 4. Setup Training Options and Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "ab015fd0-7fb4-4d5d-9fa2-30a05dbd515a",
      "metadata": {
        "id": "ab015fd0-7fb4-4d5d-9fa2-30a05dbd515a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class LossHistoryAndSave(keras.callbacks.Callback):\n",
        "    def __init__(self, file_path):\n",
        "        super().__init__()\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.file_path = file_path\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        \n",
        "        # Save loss values to a file\n",
        "        with open(self.file_path, 'a') as file:\n",
        "            file.write(f'Epoch {epoch + 1}: Training Loss: {logs.get(\"loss\")}, Validation Loss: {logs.get(\"val_loss\")}\\n')\n",
        "\n",
        "class ProduceExample(tf.keras.callbacks.Callback): \n",
        "    def __init__(self, dataset) -> None: \n",
        "        self.dataset = dataset.as_numpy_iterator()\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
        "        data = self.dataset.next()\n",
        "        yhat = self.model.predict(data[0])\n",
        "        decoded = tf.keras.backend.ctc_decode(yhat, [200,200], greedy=False)[0][0].numpy()\n",
        "        for x in range(len(yhat)):           \n",
        "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
        "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
        "            print('~'*100)\n",
        "\n",
        "def CTCLoss(y_true, y_pred):\n",
        "    \"\"\"define loss evaluation\n",
        "    y_true : ground true\n",
        "    y_pred : model predict data\n",
        "    \"\"\"\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    #ignore_longer_outputs_than_inputs=True\n",
        "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    \"\"\"learning rate\n",
        "    epoch : epoch each dataset\n",
        "    lr : learning rate\n",
        "    \"\"\"\n",
        "    if epoch < 30:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "04be90d8-2482-46f9-b513-d5f4f8001c7e",
      "metadata": {
        "id": "04be90d8-2482-46f9-b513-d5f4f8001c7e",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f53dc2aac70>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=CTCLoss)\n",
        "checkpoint_callback = ModelCheckpoint(f'{floder}/checkpoint_1/checkpoint', monitor='val_loss',save_weights_only=True)\n",
        "schedule_callback = LearningRateScheduler(scheduler)\n",
        "loss_history_and_save = LossHistoryAndSave(f\"{floder}/loss_log/loss_history.txt\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"{floder}/logs\")\n",
        "example_callback = ProduceExample(test)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model.load_weights(f'../data/checkpoint_1/checkpoint')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "    7/26000 [..............................] - ETA: 31:16:27 - loss: 104.9451"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   69/26000 [..............................] - ETA: 31:45:59 - loss: 111.4725"
          ]
        }
      ],
      "source": [
        "model.fit(train, validation_data=test, epochs=100, batch_size=64, callbacks=[example_callback, early_stopping, tensorboard_callback, loss_history_and_save, checkpoint_callback, schedule_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa8ee94b-89f7-4733-8a0c-a86f86ff590a",
      "metadata": {
        "id": "fa8ee94b-89f7-4733-8a0c-a86f86ff590a",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "# 5. Make a Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01fa7204-ce0e-49a8-8dbd-14fe5dfead40",
      "metadata": {
        "id": "01fa7204-ce0e-49a8-8dbd-14fe5dfead40",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n",
        "#output = 'checkpoints.zip'\n",
        "#gdown.download(url, output, quiet=False)\n",
        "#gdown.extractall('checkpoints.zip', 'models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1681718b-1169-410c-933f-bd051da9b718",
      "metadata": {
        "id": "1681718b-1169-410c-933f-bd051da9b718"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.optimizers import legacy\n",
        "\n",
        "# # define your optimizer as a legacy optimizer\n",
        "# optimizer = legacy.Adam()\n",
        "\n",
        "# model.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "247f664d-3c87-4e96-946e-930dad0e1c2c",
      "metadata": {
        "id": "247f664d-3c87-4e96-946e-930dad0e1c2c",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f19f8110100>"
            ]
          },
          "execution_count": 275,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model.load_weights('/home/somkiat/Lip_reading/checkpoint_1/checkpoint')\n",
        "model.load_weights(f'../data/checkpoint_1/checkpoint')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38546dc2-bee9-4837-864b-8a884df40ad7",
      "metadata": {
        "id": "38546dc2-bee9-4837-864b-8a884df40ad7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "test_data = test.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a43621f0-229d-4c0d-9554-9c3a3da9c61a",
      "metadata": {
        "id": "a43621f0-229d-4c0d-9554-9c3a3da9c61a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "sample = test_data.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-25 10:01:11.677306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
            "2023-11-25 10:01:11.715210: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
            "2023-11-25 10:01:11.770591: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.770614: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.770626: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.770637: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.770649: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.772323: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.772340: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.780016: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.795722: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:11.795738: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-25 10:01:13.362744: W tensorflow/tsl/framework/bfc_allocator.cc:366] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n"
          ]
        }
      ],
      "source": [
        "eva_true = []\n",
        "eva_pred = []\n",
        "for sample in test_data:\n",
        "    try:\n",
        "        for i in range(0, 2):\n",
        "            y_true = []\n",
        "            for j in sample[1][i]:\n",
        "                if j != 0:\n",
        "                    y_true.append(j)\n",
        "            yhat = model.predict(sample[0])\n",
        "            eva_true.append(''.join([string.decode('utf-8') for string in num_to_char(y_true).numpy()]))                                                                                      \n",
        "            y_pred = []\n",
        "            for k in yhat[i]:\n",
        "                sorted_array = np.sort(k)[::-1]\n",
        "                # Get the fifth largest value\n",
        "                top_five_indices = np.argsort(k)[-5:]\n",
        "\n",
        "                # Replace values not in the top five with 0\n",
        "                result_array = np.where(np.isin(np.arange(len(k)), top_five_indices), k, 0)\n",
        "                top_five_indices = np.argsort(result_array)[-5:]\n",
        "                result_array = np.zeros(np.max(top_five_indices) + 1)\n",
        "                result_array[top_five_indices] = top_five_indices  # Y\n",
        "                result_array = result_array[result_array != 0]\n",
        "                top_five = []\n",
        "                for x in result_array:\n",
        "                    top_five.append(x)\n",
        "                y_pred.append(top_five)\n",
        "            top_one = []\n",
        "            for m in range(0, len(y_true)):\n",
        "                if y_true[m] in y_pred[m]:\n",
        "                    top_one.append(y_true[m])\n",
        "                else:\n",
        "                    # top_one.append(max)\n",
        "                    top_one.append(79)\n",
        "            eva_pred.append(''.join([string.decode('utf-8') for string in num_to_char(top_one).numpy()]))\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['แล้ว็นการัาน',\n",
              " 'แล้วเมงไกน',\n",
              " 'ใราน',\n",
              " 'นแา',\n",
              " 'ใ้น่อง',\n",
              " 'น้องเป็นแ',\n",
              " 'กรัะค',\n",
              " 'ะ่นาค',\n",
              " 'เาะวก็อคิ',\n",
              " 'แต่รายะัััง่',\n",
              " 'งมกา',\n",
              " 'น',\n",
              " 'งก',\n",
              " 'ัอยาน',\n",
              " 'แก้อนจั',\n",
              " 'แต่วรก',\n",
              " 'แั',\n",
              " 'แา',\n",
              " 'ี',\n",
              " 'เกิัน',\n",
              " 'ราร',\n",
              " 'กัก',\n",
              " 'เะกเอกกกนนกายริง',\n",
              " 'วมา',\n",
              " 'นทกันเย',\n",
              " 'เาั่มัน',\n",
              " 'ัใก้ม',\n",
              " 'นูน',\n",
              " 'ั่ัรเรื่อง',\n",
              " 'วใัเมน',\n",
              " '่ารก',\n",
              " '',\n",
              " '่เกมนงเนี่',\n",
              " 'าง',\n",
              " 'งงเป็นน',\n",
              " 'เล่ยแนั่',\n",
              " 'ไม่ระ',\n",
              " 'นะ',\n",
              " '็ก',\n",
              " '',\n",
              " 'เาะ้กน่า',\n",
              " 'เ่่อ่งไ',\n",
              " 'ร',\n",
              " 'ียนเ',\n",
              " 'ยาไ้ย',\n",
              " 'แตรวเร็',\n",
              " 'เ็นที่',\n",
              " 'น',\n",
              " 'กอะไร',\n",
              " 'ง',\n",
              " 'น่ค',\n",
              " 'แต่กนมั่ายบ',\n",
              " 'แล้วกว',\n",
              " 'นากเ',\n",
              " 'เีวาน',\n",
              " 'แต่วระแกกน',\n",
              " 'แล้วเมานน',\n",
              " 'เ้าเนะค',\n",
              " 'ใร่',\n",
              " 'แต่ว',\n",
              " 'เ็นักาา',\n",
              " 'าวย',\n",
              " 'ันี้ะ',\n",
              " 'ไมแที่แล',\n",
              " 'เาะ้อะไราย',\n",
              " 'นเ',\n",
              " 'เงารืมีแ',\n",
              " 'นะ',\n",
              " 'แต็นก',\n",
              " 'แลวเนี่มร',\n",
              " 'ะ',\n",
              " 'ยน',\n",
              " 'เาะวั่มานแนนก',\n",
              " 'าอย',\n",
              " 'าา',\n",
              " 'าเไมกน',\n",
              " 'ั',\n",
              " 'กเ',\n",
              " 'เนงค',\n",
              " 'แตกวะ',\n",
              " 'ะูค',\n",
              " 'แ่างเ',\n",
              " 'แลวากกาน',\n",
              " 'แล้วเ็มีอไิาง',\n",
              " 'แนน่',\n",
              " 'เ็นว',\n",
              " 'น',\n",
              " 'าินบ่อ',\n",
              " 'ะมี',\n",
              " 'กับอ',\n",
              " 'ไัวะ',\n",
              " 'ะน',\n",
              " 'แล้วค',\n",
              " 'เ่า',\n",
              " 'ะ',\n",
              " '่ะก',\n",
              " 'แลกยไมรร',\n",
              " '่ทกนก',\n",
              " 'ะราอา',\n",
              " '',\n",
              " 'ก',\n",
              " 'เาะวัยเก',\n",
              " 'นาย',\n",
              " 'าวอเนะน',\n",
              " 'นนเป็นอน',\n",
              " 'ที่ไ',\n",
              " '้า',\n",
              " 'มน',\n",
              " 'เ้ันเ',\n",
              " 'ใ่นกนางน',\n",
              " 'องะ',\n",
              " 'แล้ว้วยเรก',\n",
              " '',\n",
              " 'นวว้',\n",
              " 'เาะวปานก',\n",
              " 'งอง',\n",
              " 'งกน่',\n",
              " '้ยกนเะ',\n",
              " 'าก',\n",
              " 'บ',\n",
              " 'ี่ิ',\n",
              " '่ากก่องน',\n",
              " 'อรายคมน',\n",
              " 'แล้วกา',\n",
              " 'แต่วาง',\n",
              " 'เืรองม',\n",
              " 'เ้มคร',\n",
              " 'น',\n",
              " 'านก',\n",
              " 'วั',\n",
              " 'ร',\n",
              " 'เะวเมเ',\n",
              " 'วม้ว',\n",
              " '็ม',\n",
              " 'แลี',\n",
              " 'อวายเนน',\n",
              " 'เะวนั',\n",
              " 'นว่ารอ',\n",
              " 'แล้วา',\n",
              " 'นน',\n",
              " 'เาไนค',\n",
              " 'กา',\n",
              " 'เะวััน',\n",
              " 'เ่ออารน',\n",
              " 'แล้วรนน',\n",
              " '้',\n",
              " 'า',\n",
              " 'มัวะเาก',\n",
              " 'ืวักิ',\n",
              " 'าวันั้น',\n",
              " 'มาย่',\n",
              " 'มน',\n",
              " 'นมัาก',\n",
              " 'เอนน',\n",
              " 'เะัก',\n",
              " 'แล้ววัน',\n",
              " '',\n",
              " 'นกนเนี้ม',\n",
              " 'ไม',\n",
              " 'เย',\n",
              " 'แตวเ็บไใ',\n",
              " 'นอาน',\n",
              " 'เ่อื่อรค',\n",
              " '่านะ',\n",
              " 'ไมร',\n",
              " 'แล้วเ็กีกนไ',\n",
              " 'เ่ราที่มาก',\n",
              " 'ไม',\n",
              " 'กัิอ',\n",
              " 'เก็',\n",
              " 'งอไี',\n",
              " 'นั้รยไครับ',\n",
              " '',\n",
              " 'งเงเท',\n",
              " 'นนกนก',\n",
              " 'นอทา',\n",
              " 'ีก',\n",
              " 'กาเมืักัเน',\n",
              " 'เ็นาะ',\n",
              " 'ใะี่บเนี่',\n",
              " 'เีวแ',\n",
              " 'วเนรงนค',\n",
              " 'ะ',\n",
              " 'เ็นไะ',\n",
              " 'มก็น',\n",
              " 'อะไร่าง',\n",
              " 'กมกิ',\n",
              " 'ว',\n",
              " 'ไม',\n",
              " 'ง',\n",
              " 'แเ็นเ',\n",
              " 'ก',\n",
              " 'แกกน',\n",
              " 'เา',\n",
              " 'เ่น',\n",
              " 'แล้วไมาเ้',\n",
              " 'เ',\n",
              " 'น',\n",
              " 'แล้ว',\n",
              " 'เกนวังงน',\n",
              " 'แลาน',\n",
              " 'นกน',\n",
              " 'ก็',\n",
              " 'ใมากะค',\n",
              " 'นงเี',\n",
              " 'เะวัก',\n",
              " 'แตวน่ะ',\n",
              " 'แวรงคป',\n",
              " 'น่ค',\n",
              " 'ไ',\n",
              " 'นรงแา',\n",
              " '่',\n",
              " 'เ็นครอก',\n",
              " 'ะก้องมาคอน',\n",
              " 'ร่',\n",
              " 'ไม่',\n",
              " 'แตะม',\n",
              " 'า',\n",
              " 'แล้วงไานก',\n",
              " 'น่',\n",
              " 'แลอย',\n",
              " '',\n",
              " '',\n",
              " 'งเมื่อกา',\n",
              " 'อะ่าง',\n",
              " 'นนนเ',\n",
              " 'ะ',\n",
              " 'แต่วยน',\n",
              " 'เาะวาักคา',\n",
              " 'เาะวนาน',\n",
              " 'ไมวัป',\n",
              " 'ที่อกาน',\n",
              " 'มัแิ',\n",
              " 'เวนนงนร',\n",
              " '่าน',\n",
              " 'เะวัแ',\n",
              " 'นไก',\n",
              " '',\n",
              " 'เ',\n",
              " 'านัน',\n",
              " 'น',\n",
              " 'แ่ร',\n",
              " 'นคอรกน',\n",
              " 'เ็ววนน',\n",
              " 'เ็นเมกน',\n",
              " 'เ็น',\n",
              " 'แล้วน',\n",
              " 'แตว่าบ',\n",
              " '่านไ',\n",
              " 'แาัก',\n",
              " 'วน',\n",
              " 'เ้าแกไเนไย',\n",
              " '่าังเ',\n",
              " 'ไเว',\n",
              " 'น',\n",
              " 'งน่',\n",
              " 'น',\n",
              " '่',\n",
              " '้อง',\n",
              " 'นวนัร',\n",
              " 'อ่น',\n",
              " 'งน',\n",
              " 'เัอินเใ',\n",
              " 'ะา',\n",
              " 'นก',\n",
              " 'าน่',\n",
              " 'ใน',\n",
              " '',\n",
              " 'งไ',\n",
              " 'อเก',\n",
              " 'ก่นกทน',\n",
              " 'อน่ค',\n",
              " 'เ่อนี้',\n",
              " 'เ่นน',\n",
              " 'ีอนม',\n",
              " 'แลกวน',\n",
              " 'แลมา',\n",
              " 'ก็ม',\n",
              " 'เ',\n",
              " 'งยกน',\n",
              " 'กาก่ะเ',\n",
              " 'นู่น',\n",
              " 'แล้วรรค',\n",
              " 'งาย',\n",
              " 'น',\n",
              " 'เากัน',\n",
              " 'วรอม่ั',\n",
              " 'ใ้นเ',\n",
              " 'แล้วักไ',\n",
              " 'มั',\n",
              " 'นค',\n",
              " 'ในกา',\n",
              " 'อกก่าัง',\n",
              " '้',\n",
              " 'เัองา',\n",
              " 'แต่',\n",
              " 'น',\n",
              " 'นเ',\n",
              " 'แต่ไะ',\n",
              " 'าาแ',\n",
              " 'แล่ารับเเไ่',\n",
              " 'ไม่นกับ',\n",
              " 'มั่กเล',\n",
              " 'แต่้นเีนนก',\n",
              " 'มยครักัน',\n",
              " '',\n",
              " '',\n",
              " 'าย',\n",
              " 'เ่วง',\n",
              " 'างแ',\n",
              " '้ก่าน',\n",
              " 'เมนั่',\n",
              " 'แวาากอนนเ',\n",
              " 'เไอ']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eva_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "314\n",
            "314\n"
          ]
        }
      ],
      "source": [
        "print(len(eva_true))\n",
        "print(len(eva_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Char Error Rate: 0.828020037906062\n"
          ]
        }
      ],
      "source": [
        "eva = []\n",
        "for i in range(0, len(eva_true)):\n",
        "    error = cer(eva_true[i], eva_pred[i])\n",
        "    eva.append(error)\n",
        "# Print the result\n",
        "print(f\"Average Char Error Rate: {sum(eva) / len(eva)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# y_true = [string.decode('utf-8') for string in num_to_char(y_true).numpy()]\n",
        "# y_pred = [string.decode('utf-8') for string in num_to_char(top_one).numpy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "All arrays must be of the same length",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/somkiat/Lip_reading/model/LipNet.ipynb Cell 48\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Creating a DataFrame\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame({\u001b[39m'\u001b[39;49m\u001b[39my_true\u001b[39;49m\u001b[39m'\u001b[39;49m: y_true, \u001b[39m'\u001b[39;49m\u001b[39my_pred\u001b[39;49m\u001b[39m'\u001b[39;49m: y_pred})\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Display the DataFrame\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e35302e33372e3232222c2275736572223a22736f6d6b696174227d/home/somkiat/Lip_reading/model/LipNet.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mhead(\u001b[39m29\u001b[39m))\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/pandas/core/frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    727\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[1;32m    728\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[1;32m    734\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[1;32m    735\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
            "File \u001b[0;32m~/miniconda3/envs/LipNet_3/lib/python3.9/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating a DataFrame\n",
        "df = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df.head(29))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# yhat = model.predict(sample[0])\n",
        "# for i in yhat:\n",
        "#     index = i[81]\n",
        "#     sorted_array = np.sort(index)[::-1]\n",
        "#     # Get the fifth largest value\n",
        "#     top_five_indices = np.argsort(index)[-5:]\n",
        "\n",
        "#     # Replace values not in the top five with 0\n",
        "#     result_array = np.where(np.isin(np.arange(len(index)), top_five_indices), index, 0)\n",
        "#     top_five_indices = np.argsort(result_array)[-5:]\n",
        "#     print(top_five_indices)\n",
        "#     result_array = np.zeros(max(top_five_indices) + 1)\n",
        "#     result_array[top_five_indices] = top_five_indices  # Y\n",
        "#     result_array = result_array[result_array != 0]\n",
        "#     for i in result_array:\n",
        "#         print(int(i))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# result_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# decoded = tf.keras.backend.ctc_decode(result_array, input_length=[200,200], greedy=True).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 56ms/step\n",
            "78\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n",
            "[\"ความเกิดจากนี้\", \"หรือบางทีดูชื่อเว็บไซต์อย่างเดียวไม่พอค่ะ\"]\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n",
            "[\"ะ\", \"\"]\n",
            "[46  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1]\n"
          ]
        }
      ],
      "source": [
        "# yhat = model.predict(sample[0])\n",
        "# print(np.argmax(yhat[0][0]))\n",
        "# print('~'*100, 'REAL TEXT')\n",
        "# tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]])\n",
        "# decoded = tf.keras.backend.ctc_decode(yhat, input_length=[200,200], greedy=True)[0][0].numpy()\n",
        "# print('~'*100, 'PREDICTIONS')\n",
        "# tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded])  \n",
        "# print(decoded[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #sample = test_data.next()\n",
        "# for sample in test_data:\n",
        "#     yhat = model.predict(sample[0])\n",
        "#     print('~'*100, 'REAL TEXT')\n",
        "#     tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]])\n",
        "#     decoded = tf.keras.backend.ctc_decode(yhat, input_length=[200,200], greedy=True)[0][0].numpy()\n",
        "#     print('~'*100, 'PREDICTIONS')\n",
        "#     tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded])    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea462999-f87e-4a7e-a057-5be7b6d8f7d5",
      "metadata": {
        "id": "ea462999-f87e-4a7e-a057-5be7b6d8f7d5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# print('~'*100, 'REAL TEXT')\n",
        "# tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82bd4c10-dd6e-411e-834b-2a3b43fd12c5",
      "metadata": {
        "id": "82bd4c10-dd6e-411e-834b-2a3b43fd12c5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d68ac46-c90b-4eab-a709-f19aee569ff5",
      "metadata": {
        "id": "5d68ac46-c90b-4eab-a709-f19aee569ff5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# print('~'*100, 'PREDICTIONS')\n",
        "# tf.print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64622f98-e99b-4fed-a2cc-f0da82eb5431",
      "metadata": {
        "id": "64622f98-e99b-4fed-a2cc-f0da82eb5431",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "# Test on a Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8b0c4d0-2031-4331-b91d-d87b1ae6f6e2",
      "metadata": {
        "id": "a8b0c4d0-2031-4331-b91d-d87b1ae6f6e2"
      },
      "outputs": [],
      "source": [
        "#sample = load_data(tf.convert_to_tensor('.\\\\data\\\\s1\\\\bras9a.mpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cca60e4-47a9-4683-8a75-48f4684f723d",
      "metadata": {
        "id": "0cca60e4-47a9-4683-8a75-48f4684f723d"
      },
      "outputs": [],
      "source": [
        "# print('~'*100, 'REAL TEXT')\n",
        "# [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [sample[1]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc5037c-1e32-435c-b0cc-01e1fb3b863c",
      "metadata": {
        "id": "8cc5037c-1e32-435c-b0cc-01e1fb3b863c"
      },
      "outputs": [],
      "source": [
        "# yhat = model.predict(tf.expand_dims(sample[0], axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c4f77d-715d-409f-bc5e-3ebe48704e8f",
      "metadata": {
        "id": "22c4f77d-715d-409f-bc5e-3ebe48704e8f"
      },
      "outputs": [],
      "source": [
        "# decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4d12ecc-b634-499e-a4bc-db9f010835fb",
      "metadata": {
        "id": "e4d12ecc-b634-499e-a4bc-db9f010835fb"
      },
      "outputs": [],
      "source": [
        "# print('~'*100, 'PREDICTIONS')\n",
        "# [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58712ecc-5ac7-4c65-b341-7258aad68e28",
      "metadata": {
        "id": "58712ecc-5ac7-4c65-b341-7258aad68e28"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20a647bd-9a1b-4e6c-9f47-19ddb13c3dbf",
      "metadata": {
        "id": "20a647bd-9a1b-4e6c-9f47-19ddb13c3dbf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
